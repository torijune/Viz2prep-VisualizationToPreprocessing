"""
ë©€í‹°ëª¨ë‹¬ ì „ì²˜ë¦¬ ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸
í†µê³„ ì •ë³´ì™€ ì‹œê°í™”ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ì²˜ë¦¬ ì½”ë“œë¥¼ ìƒì„±í•˜ëŠ” ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import pandas as pd
import numpy as np
import os
from dotenv import load_dotenv
from agents.data_loader import data_loader
from agents.statistics_agent import statistics_agent
from agents.visualization_agent import visualization_agent
from agents.preprocessing_agent import preprocessing_agent

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()


def create_test_dataset():
    """
    í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°ì…‹ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    np.random.seed(42)
    
    # Titanic ë°ì´í„°ì™€ ìœ ì‚¬í•œ êµ¬ì¡°ì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    n_samples = 100
    
    # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë“¤
    age = np.random.normal(30, 10, n_samples)
    age = np.clip(age, 1, 80)  # ë‚˜ì´ ë²”ìœ„ ì œí•œ
    
    fare = np.random.exponential(30, n_samples)
    fare = np.clip(fare, 0, 500)  # ìš”ê¸ˆ ë²”ìœ„ ì œí•œ
    
    # ë²”ì£¼í˜• ë³€ìˆ˜ë“¤
    sex = np.random.choice(['male', 'female'], n_samples)
    pclass = np.random.choice([1, 2, 3], n_samples)
    embarked = np.random.choice(['S', 'C', 'Q'], n_samples)
    
    # ê²°ì¸¡ê°’ ì¶”ê°€
    age[np.random.choice(n_samples, 10, replace=False)] = np.nan
    fare[np.random.choice(n_samples, 5, replace=False)] = np.nan
    embarked[np.random.choice(n_samples, 8, replace=False)] = np.nan
    
    # íƒ€ê²Ÿ ë³€ìˆ˜ (ìƒì¡´ ì—¬ë¶€)
    # ë‚˜ì´, ì„±ë³„, ìš”ê¸ˆ, í´ë˜ìŠ¤ì— ê¸°ë°˜í•œ ê°„ë‹¨í•œ ë¡œì§
    survival_prob = (
        (age < 30) * 0.8 +  # ì Šì€ ì‚¬ëŒì€ ìƒì¡´ í™•ë¥  ë†’ìŒ
        (sex == 'female') * 0.7 +  # ì—¬ì„±ì€ ìƒì¡´ í™•ë¥  ë†’ìŒ
        (pclass == 1) * 0.6 +  # 1ë“±ê¸‰ì€ ìƒì¡´ í™•ë¥  ë†’ìŒ
        (fare > 50) * 0.4  # ê³ ê¸‰ ìš”ê¸ˆì€ ìƒì¡´ í™•ë¥  ë†’ìŒ
    ) / 4
    
    survived = np.random.binomial(1, np.clip(survival_prob, 0, 1))
    
    # DataFrame ìƒì„±
    df = pd.DataFrame({
        'PassengerId': range(1, n_samples + 1),
        'Survived': survived,
        'Pclass': pclass,
        'Name': [f'Passenger_{i}' for i in range(1, n_samples + 1)],
        'Sex': sex,
        'Age': age,
        'SibSp': np.random.poisson(1, n_samples),
        'Parch': np.random.poisson(0.5, n_samples),
        'Ticket': [f'Ticket_{i}' for i in range(1, n_samples + 1)],
        'Fare': fare,
        'Cabin': [f'Cabin_{i}' if np.random.random() > 0.7 else np.nan for i in range(1, n_samples + 1)],
        'Embarked': embarked
    })
    
    return df


def test_multimodal_preprocessing():
    """
    ë©€í‹°ëª¨ë‹¬ ì „ì²˜ë¦¬ ì—ì´ì „íŠ¸ë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
    """
    print("="*80)
    print("ë©€í‹°ëª¨ë‹¬ ì „ì²˜ë¦¬ ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸")
    print("="*80)
    
    # 1. í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ìƒì„±
    print("1. í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ìƒì„± ì¤‘...")
    test_df = create_test_dataset()
    test_df.to_csv('test_titanic.csv', index=False)
    print(f"   ìƒì„±ëœ ë°ì´í„° í¬ê¸°: {test_df.shape}")
    print(f"   ê²°ì¸¡ê°’ ê°œìˆ˜: {test_df.isnull().sum().sum()}")
    
    # 2. ë°ì´í„° ë¡œë“œ
    print("\n2. ë°ì´í„° ë¡œë“œ ì¤‘...")
    data_result = data_loader.invoke({"file_path": "test_titanic.csv"})
    df = data_result['dataframe']
    print(f"   ë¡œë“œëœ ë°ì´í„° í¬ê¸°: {df.shape}")
    
    # 3. í†µê³„ ì •ë³´ ìƒì„±
    print("\n3. í†µê³„ ì •ë³´ ìƒì„± ì¤‘...")
    stats_result = statistics_agent.invoke({"dataframe": df})
    statistics_text = stats_result['statistics_text']
    print(f"   í†µê³„ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(statistics_text)}")
    print("   í†µê³„ ì •ë³´ ë¯¸ë¦¬ë³´ê¸°:")
    print("   " + statistics_text[:200] + "...")
    
    # 4. ì‹œê°í™” ìƒì„±
    print("\n4. ì‹œê°í™” ìƒì„± ì¤‘...")
    viz_result = visualization_agent.invoke({"dataframe": df})
    plot_paths = viz_result['plot_paths']
    print(f"   ìƒì„±ëœ í”Œë¡¯ ìˆ˜: {len(plot_paths)}")
    for i, path in enumerate(plot_paths, 1):
        if os.path.exists(path):
            print(f"   {i}. {path} ({os.path.getsize(path)} bytes)")
    
    # 5. ë©€í‹°ëª¨ë‹¬ ì „ì²˜ë¦¬ ì—ì´ì „íŠ¸ ì‹¤í–‰
    print("\n5. ë©€í‹°ëª¨ë‹¬ ì „ì²˜ë¦¬ ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘...")
    print("   (OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤)")
    
    # OpenAI API í‚¤ í™•ì¸
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("   âš ï¸  OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   env.example íŒŒì¼ì„ .envë¡œ ë³µì‚¬í•˜ê³  API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        return
    
    try:
        # ì „ì²˜ë¦¬ ì—ì´ì „íŠ¸ ì‹¤í–‰
        preprocessing_input = {
            "dataframe": df,
            "text_analysis": statistics_text,
            "plot_paths": plot_paths
        }
        
        preprocessing_result = preprocessing_agent.invoke(preprocessing_input)
        
        # ê²°ê³¼ ì¶œë ¥
        print("\n" + "="*80)
        print("ë©€í‹°ëª¨ë‹¬ ì „ì²˜ë¦¬ ê²°ê³¼")
        print("="*80)
        
        print(f"ğŸ“Š ì›ë³¸ ë°ì´í„° í¬ê¸°: {df.shape}")
        print(f"ğŸ”§ ì „ì²˜ë¦¬ëœ ë°ì´í„° í¬ê¸°: {preprocessing_result['preprocessed_dataframe'].shape}")
        
        if 'preprocessing_code' in preprocessing_result:
            code = preprocessing_result['preprocessing_code']
            print(f"ğŸ’» ìƒì„±ëœ ì „ì²˜ë¦¬ ì½”ë“œ ê¸¸ì´: {len(code)} ë¬¸ì")
            print("\nìƒì„±ëœ ì „ì²˜ë¦¬ ì½”ë“œ:")
            print("-" * 50)
            print(code)
            print("-" * 50)
        
        # ì „ì²˜ë¦¬ ì „í›„ ë¹„êµ
        print("\nğŸ“ˆ ì „ì²˜ë¦¬ ì „í›„ ë¹„êµ:")
        print(f"   ì›ë³¸ ê²°ì¸¡ê°’: {df.isnull().sum().sum()}")
        print(f"   ì „ì²˜ë¦¬ í›„ ê²°ì¸¡ê°’: {preprocessing_result['preprocessed_dataframe'].isnull().sum().sum()}")
        
        print("\nâœ… ë©€í‹°ëª¨ë‹¬ ì „ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ì „ì²˜ë¦¬ ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        # í…ŒìŠ¤íŠ¸ íŒŒì¼ ì •ë¦¬
        if os.path.exists('test_titanic.csv'):
            os.remove('test_titanic.csv')


if __name__ == "__main__":
    test_multimodal_preprocessing() 