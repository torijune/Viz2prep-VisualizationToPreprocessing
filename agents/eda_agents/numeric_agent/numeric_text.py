"""
ì—°ì†í˜• ë°ì´í„° í†µê³„ì¹˜ ë¶„ì„ í…ìŠ¤íŠ¸ ì—ì´ì „íŠ¸
Min, Max, Mean, ë¶„í¬ ì™œë„, ì²¨ë„ ë“±ì„ ë¶„ì„í•˜ì—¬ í…ìŠ¤íŠ¸ í˜•íƒœë¡œ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
"""

import pandas as pd
import numpy as np
from typing import Dict, Any
from langchain_core.runnables import RunnableLambda
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage


def analyze_numeric_statistics(inputs: Dict[str, Any]) -> Dict[str, Any]:
    """
    ì—°ì†í˜• ë°ì´í„°ì˜ í†µê³„ì¹˜ë¥¼ ë¶„ì„í•˜ê³  í…ìŠ¤íŠ¸ í˜•íƒœë¡œ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    
    Args:
        inputs: DataFrameì´ í¬í•¨ëœ ì…ë ¥ ë”•ì…”ë„ˆë¦¬
        
    Returns:
        ì—°ì†í˜• ë°ì´í„° í†µê³„ ë¶„ì„ ê²°ê³¼ê°€ í¬í•¨ëœ ë”•ì…”ë„ˆë¦¬
    """
    df = inputs["dataframe"]
    
    # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ë§Œ ì„ íƒ
    numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()
    
    if not numeric_columns:
        return {
            **inputs,
            "numeric_analysis": "ìˆ˜ì¹˜í˜• ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
        }
    
    # ê¸°ë³¸ í†µê³„ ë¶„ì„
    stats_analysis = {}
    for col in numeric_columns:
        stats = df[col].describe()
        skewness = df[col].skew()
        kurtosis = df[col].kurtosis()
        
        stats_analysis[col] = {
            'count': stats['count'],
            'mean': stats['mean'],
            'std': stats['std'],
            'min': stats['min'],
            '25%': stats['25%'],
            '50%': stats['50%'],
            '75%': stats['75%'],
            'max': stats['max'],
            'skewness': skewness,
            'kurtosis': kurtosis
        }
    
    # ë¶„ì„ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    analysis_text = "=== ì—°ì†í˜• ë°ì´í„° í†µê³„ ë¶„ì„ ===\n\n"
    
    for col, stats in stats_analysis.items():
        analysis_text += f"ğŸ“Š {col} ì»¬ëŸ¼ ë¶„ì„:\n"
        analysis_text += f"   - ê¸°ë³¸ í†µê³„: count={stats['count']:.0f}, mean={stats['mean']:.2f}, std={stats['std']:.2f}\n"
        analysis_text += f"   - ë²”ìœ„: min={stats['min']:.2f}, max={stats['max']:.2f}\n"
        analysis_text += f"   - ì‚¬ë¶„ìœ„ìˆ˜: Q1={stats['25%']:.2f}, Q2={stats['50%']:.2f}, Q3={stats['75%']:.2f}\n"
        analysis_text += f"   - ë¶„í¬ íŠ¹ì„±: ì™œë„={stats['skewness']:.2f}, ì²¨ë„={stats['kurtosis']:.2f}\n"
        
        # ë¶„í¬ í•´ì„
        if abs(stats['skewness']) < 0.5:
            skew_interpretation = "ëŒ€ì¹­ ë¶„í¬"
        elif stats['skewness'] > 0:
            skew_interpretation = "ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì¹˜ìš°ì¹œ ë¶„í¬"
        else:
            skew_interpretation = "ì™¼ìª½ìœ¼ë¡œ ì¹˜ìš°ì¹œ ë¶„í¬"
        
        if stats['kurtosis'] > 3:
            kurt_interpretation = "ë¾°ì¡±í•œ ë¶„í¬ (ì²¨ë„ ë†’ìŒ)"
        elif stats['kurtosis'] < 3:
            kurt_interpretation = "ë„“ì€ ë¶„í¬ (ì²¨ë„ ë‚®ìŒ)"
        else:
            kurt_interpretation = "ì •ìƒ ë¶„í¬"
        
        analysis_text += f"   - ë¶„í¬ í•´ì„: {skew_interpretation}, {kurt_interpretation}\n\n"
    
    # ì „ì²´ ìˆ˜ì¹˜í˜• ë°ì´í„° ìš”ì•½
    analysis_text += "=== ì „ì²´ ìˆ˜ì¹˜í˜• ë°ì´í„° ìš”ì•½ ===\n"
    analysis_text += f"- ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ìˆ˜: {len(numeric_columns)}ê°œ\n"
    analysis_text += f"- ì»¬ëŸ¼ ëª©ë¡: {', '.join(numeric_columns)}\n"
    
    # ìƒê´€ê´€ê³„ ë¶„ì„ (ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ì´ 2ê°œ ì´ìƒì¸ ê²½ìš°)
    if len(numeric_columns) >= 2:
        correlation_matrix = df[numeric_columns].corr()
        analysis_text += f"\n=== ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ ===\n"
        analysis_text += correlation_matrix.to_string()
    
    try:
        # LLMì„ ì‚¬ìš©í•˜ì—¬ ì¶”ê°€ ì¸ì‚¬ì´íŠ¸ ìƒì„±
        llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0.1,
            max_tokens=1000
        )
        
        llm_prompt = f"""
        ë‹¤ìŒì€ ë°ì´í„°ì…‹ì˜ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ í†µê³„ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤:

        {analysis_text}

        ìœ„ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:

        1. **ì£¼ìš” ë°œê²¬ì‚¬í•­**: ê°€ì¥ ì¤‘ìš”í•œ í†µê³„ì  íŠ¹ì§•ë“¤ì„ ìš”ì•½
        2. **ë¶„í¬ íŠ¹ì„±**: ê° ë³€ìˆ˜ì˜ ë¶„í¬ í˜•íƒœì™€ ì˜ë¯¸ í•´ì„
        3. **ì´ìƒì¹˜ ê°€ëŠ¥ì„±**: í†µê³„ì¹˜ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ìƒì¹˜ê°€ ìˆì„ ìˆ˜ ìˆëŠ” ë³€ìˆ˜ ì‹ë³„
        4. **ì „ì²˜ë¦¬ ê¶Œì¥ì‚¬í•­**: ìŠ¤ì¼€ì¼ë§, ì •ê·œí™” ë“±ì˜ ì „ì²˜ë¦¬ ë°©ë²• ì œì•ˆ

        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:

        ## ì£¼ìš” ë°œê²¬ì‚¬í•­
        [ê°€ì¥ ì¤‘ìš”í•œ í†µê³„ì  íŠ¹ì§•ë“¤]

        ## ë¶„í¬ íŠ¹ì„± ë¶„ì„
        [ê° ë³€ìˆ˜ì˜ ë¶„í¬ í˜•íƒœì™€ ì˜ë¯¸]

        ## ì´ìƒì¹˜ íƒì§€ íŒíŠ¸
        [ì´ìƒì¹˜ê°€ ìˆì„ ê°€ëŠ¥ì„±ì´ ë†’ì€ ë³€ìˆ˜ë“¤]

        ## ì „ì²˜ë¦¬ ê¶Œì¥ì‚¬í•­
        [ìˆ˜ì¹˜í˜• ë³€ìˆ˜ì— ëŒ€í•œ ì „ì²˜ë¦¬ ë°©ë²• ì œì•ˆ]
        """
        
        response = llm.invoke([HumanMessage(content=llm_prompt)])
        llm_insights = response.content
        
        analysis_text += f"\n\n=== LLM ì¶”ê°€ ì¸ì‚¬ì´íŠ¸ ===\n{llm_insights}"
        
    except Exception as e:
        print(f"LLM ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
    
    print("ì—°ì†í˜• ë°ì´í„° í†µê³„ ë¶„ì„ ì™„ë£Œ")
    
    return {
        **inputs,
        "numeric_analysis": analysis_text
    }


# LangGraph ë…¸ë“œë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í•¨ìˆ˜
numeric_text_agent = RunnableLambda(analyze_numeric_statistics)
