"""
ë³€ìˆ˜ë³„ ìƒê´€ê´€ê³„ ë¶„ì„ í…ìŠ¤íŠ¸ ì—ì´ì „íŠ¸
í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜, corr() í•¨ìˆ˜, íƒ€ê²Ÿ ë³€ìˆ˜ì™€ì˜ ìƒê´€ê´€ê³„ ë“±ì„ ë¶„ì„í•˜ì—¬ í…ìŠ¤íŠ¸ í˜•íƒœë¡œ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
"""

import pandas as pd
import numpy as np
from typing import Dict, Any
from langchain_core.runnables import RunnableLambda
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage


def analyze_correlations(inputs: Dict[str, Any]) -> Dict[str, Any]:
    """
    ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ë¥¼ ë¶„ì„í•˜ê³  í…ìŠ¤íŠ¸ í˜•íƒœë¡œ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    
    Args:
        inputs: DataFrameì´ í¬í•¨ëœ ì…ë ¥ ë”•ì…”ë„ˆë¦¬
        
    Returns:
        ìƒê´€ê´€ê³„ ë¶„ì„ ê²°ê³¼ê°€ í¬í•¨ëœ ë”•ì…”ë„ˆë¦¬
    """
    df = inputs["dataframe"]
    
    # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ë§Œ ì„ íƒ
    numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()
    
    if len(numeric_columns) < 2:
        return {
            **inputs,
            "correlation_analysis": "ìˆ˜ì¹˜í˜• ë³€ìˆ˜ê°€ 2ê°œ ë¯¸ë§Œì´ì–´ì„œ ìƒê´€ê´€ê³„ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        }
    
    # ë¶„ì„ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    analysis_text = "=== ë³€ìˆ˜ë³„ ìƒê´€ê´€ê³„ ë¶„ì„ ===\n\n"
    
    # 1. ì „ì²´ ìƒê´€ê´€ê³„ í–‰ë ¬
    correlation_matrix = df[numeric_columns].corr()
    
    analysis_text += "ğŸ“Š ì „ì²´ ìƒê´€ê´€ê³„ í–‰ë ¬:\n"
    analysis_text += correlation_matrix.to_string()
    analysis_text += "\n\n"
    
    # 2. íƒ€ê²Ÿ ë³€ìˆ˜ ì‹ë³„ ë° ë¶„ì„
    target_column = None
    for col in ['Survived', 'target', 'label', 'class', 'y']:
        if col in numeric_columns:
            target_column = col
            break
    
    if target_column:
        analysis_text += f"ğŸ¯ íƒ€ê²Ÿ ë³€ìˆ˜ ({target_column})ì™€ì˜ ìƒê´€ê´€ê³„:\n"
        
        # íƒ€ê²Ÿ ë³€ìˆ˜ì™€ì˜ ìƒê´€ê´€ê³„
        target_correlations = correlation_matrix[target_column].sort_values(key=abs, ascending=False)
        
        for col in target_correlations.index:
            if col != target_column:
                corr_value = target_correlations[col]
                analysis_text += f"   - {col}: {corr_value:.4f}"
                
                # ìƒê´€ê´€ê³„ ê°•ë„ í•´ì„
                if abs(corr_value) >= 0.7:
                    strength = "ë§¤ìš° ê°•í•¨"
                elif abs(corr_value) >= 0.5:
                    strength = "ê°•í•¨"
                elif abs(corr_value) >= 0.3:
                    strength = "ë³´í†µ"
                elif abs(corr_value) >= 0.1:
                    strength = "ì•½í•¨"
                else:
                    strength = "ë§¤ìš° ì•½í•¨"
                
                direction = "ì–‘ì˜" if corr_value > 0 else "ìŒì˜"
                analysis_text += f" ({direction} {strength})\n"
        
        analysis_text += "\n"
    
    # 3. ê°•í•œ ìƒê´€ê´€ê³„ ë¶„ì„
    analysis_text += "ğŸ” ê°•í•œ ìƒê´€ê´€ê³„ ë¶„ì„ (|r| >= 0.5):\n"
    
    strong_correlations = []
    for i, col1 in enumerate(numeric_columns):
        for j, col2 in enumerate(numeric_columns[i+1:], i+1):
            corr_value = correlation_matrix.loc[col1, col2]
            if abs(corr_value) >= 0.5:
                strong_correlations.append({
                    'var1': col1,
                    'var2': col2,
                    'correlation': corr_value
                })
    
    if strong_correlations:
        # ì ˆëŒ“ê°’ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        strong_correlations.sort(key=lambda x: abs(x['correlation']), reverse=True)
        
        for corr in strong_correlations:
            direction = "ì–‘ì˜" if corr['correlation'] > 0 else "ìŒì˜"
            analysis_text += f"   - {corr['var1']} â†” {corr['var2']}: {corr['correlation']:.4f} ({direction} ê°•í•œ ìƒê´€ê´€ê³„)\n"
    else:
        analysis_text += "   - ê°•í•œ ìƒê´€ê´€ê³„(|r| >= 0.5)ê°€ ìˆëŠ” ë³€ìˆ˜ ìŒì´ ì—†ìŠµë‹ˆë‹¤.\n"
    
    analysis_text += "\n"
    
    # 4. ë‹¤ì¤‘ê³µì„ ì„± ë¶„ì„
    analysis_text += "âš ï¸ ë‹¤ì¤‘ê³µì„ ì„± ë¶„ì„:\n"
    
    # ìƒê´€ê³„ìˆ˜ 0.8 ì´ìƒì¸ ë³€ìˆ˜ ìŒ
    multicollinearity_pairs = []
    for i, col1 in enumerate(numeric_columns):
        for j, col2 in enumerate(numeric_columns[i+1:], i+1):
            corr_value = correlation_matrix.loc[col1, col2]
            if abs(corr_value) >= 0.8:
                multicollinearity_pairs.append({
                    'var1': col1,
                    'var2': col2,
                    'correlation': corr_value
                })
    
    if multicollinearity_pairs:
        analysis_text += "   - ë‹¤ì¤‘ê³µì„ ì„±ì´ ì˜ì‹¬ë˜ëŠ” ë³€ìˆ˜ ìŒ (|r| >= 0.8):\n"
        for pair in multicollinearity_pairs:
            analysis_text += f"     * {pair['var1']} â†” {pair['var2']}: {pair['correlation']:.4f}\n"
        analysis_text += "   - ê¶Œì¥ì‚¬í•­: ë³€ìˆ˜ ì„ íƒ ì‹œ í•˜ë‚˜ë§Œ ì‚¬ìš©í•˜ê±°ë‚˜, ì£¼ì„±ë¶„ ë¶„ì„ ê³ ë ¤\n"
    else:
        analysis_text += "   - ì‹¬ê°í•œ ë‹¤ì¤‘ê³µì„ ì„± ë¬¸ì œëŠ” ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"
    
    analysis_text += "\n"
    
    # 5. ìƒê´€ê´€ê³„ íŒ¨í„´ ë¶„ì„
    analysis_text += "ğŸ“ˆ ìƒê´€ê´€ê³„ íŒ¨í„´ ë¶„ì„:\n"
    
    # í‰ê·  ìƒê´€ê´€ê³„
    mean_correlation = correlation_matrix.values[np.triu_indices_from(correlation_matrix.values, k=1)].mean()
    analysis_text += f"   - í‰ê·  ìƒê´€ê´€ê³„: {mean_correlation:.4f}\n"
    
    # ìƒê´€ê´€ê³„ ë¶„í¬
    all_correlations = correlation_matrix.values[np.triu_indices_from(correlation_matrix.values, k=1)]
    positive_corr = (all_correlations > 0).sum()
    negative_corr = (all_correlations < 0).sum()
    zero_corr = (all_correlations == 0).sum()
    
    analysis_text += f"   - ì–‘ì˜ ìƒê´€ê´€ê³„: {positive_corr}ê°œ\n"
    analysis_text += f"   - ìŒì˜ ìƒê´€ê´€ê³„: {negative_corr}ê°œ\n"
    analysis_text += f"   - ë¬´ìƒê´€: {zero_corr}ê°œ\n"
    
    # 6. íŠ¹ì„± ì„ íƒì„ ìœ„í•œ ìƒê´€ê´€ê³„ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
    analysis_text += "\nğŸ“‹ íŠ¹ì„± ì„ íƒ ê¶Œì¥ì‚¬í•­:\n"
    
    if target_column:
        # íƒ€ê²Ÿ ë³€ìˆ˜ì™€ì˜ ìƒê´€ê´€ê³„ê°€ ë†’ì€ ë³€ìˆ˜ë“¤
        high_target_corr = target_correlations[abs(target_correlations) >= 0.3].index.tolist()
        high_target_corr = [col for col in high_target_corr if col != target_column]
        
        if high_target_corr:
            analysis_text += f"   - íƒ€ê²Ÿ ë³€ìˆ˜ì™€ ìƒê´€ê´€ê³„ê°€ ë†’ì€ ë³€ìˆ˜ë“¤ (|r| >= 0.3):\n"
            for col in high_target_corr:
                corr_value = target_correlations[col]
                analysis_text += f"     * {col}: {corr_value:.4f}\n"
        else:
            analysis_text += "   - íƒ€ê²Ÿ ë³€ìˆ˜ì™€ ìƒê´€ê´€ê³„ê°€ ë†’ì€ ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.\n"
    
    # ë‹¤ì¤‘ê³µì„ ì„±ì´ ìˆëŠ” ë³€ìˆ˜ë“¤
    if multicollinearity_pairs:
        analysis_text += "   - ë‹¤ì¤‘ê³µì„ ì„±ìœ¼ë¡œ ì¸í•´ ì œê±° ê³ ë ¤í•  ë³€ìˆ˜ë“¤:\n"
        vars_to_remove = set()
        for pair in multicollinearity_pairs:
            if target_column and target_column in [pair['var1'], pair['var2']]:
                # íƒ€ê²Ÿ ë³€ìˆ˜ëŠ” ì œê±°í•˜ì§€ ì•ŠìŒ
                other_var = pair['var2'] if pair['var1'] == target_column else pair['var1']
                vars_to_remove.add(other_var)
            else:
                # ìƒê´€ê³„ìˆ˜ê°€ ë” ë‚®ì€ ë³€ìˆ˜ ì œê±°
                vars_to_remove.add(pair['var1'] if abs(pair['correlation']) < 0.9 else pair['var2'])
        
        for var in vars_to_remove:
            analysis_text += f"     * {var}\n"
    
    try:
        # LLMì„ ì‚¬ìš©í•˜ì—¬ ì¶”ê°€ ì¸ì‚¬ì´íŠ¸ ìƒì„±
        llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0.1,
            max_tokens=1000
        )
        
        llm_prompt = f"""
        ë‹¤ìŒì€ ë°ì´í„°ì…‹ì˜ ìƒê´€ê´€ê³„ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤:

        {analysis_text}

        ìœ„ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:

        1. **ì£¼ìš” ë°œê²¬ì‚¬í•­**: ê°€ì¥ ì¤‘ìš”í•œ ìƒê´€ê´€ê³„ íŒ¨í„´ë“¤ì„ ìš”ì•½
        2. **ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸**: ìƒê´€ê´€ê³„ê°€ ë¹„ì¦ˆë‹ˆìŠ¤ì ìœ¼ë¡œ ì˜ë¯¸í•˜ëŠ” ë°”
        3. **ëª¨ë¸ë§ ì „ëµ**: ìƒê´€ê´€ê³„ë¥¼ ê³ ë ¤í•œ ëª¨ë¸ë§ ì „ëµ ì œì•ˆ
        4. **íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§**: ìƒê´€ê´€ê³„ë¥¼ í™œìš©í•œ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ ì•„ì´ë””ì–´

        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:

        ## ì£¼ìš” ë°œê²¬ì‚¬í•­
        [ê°€ì¥ ì¤‘ìš”í•œ ìƒê´€ê´€ê³„ íŒ¨í„´ë“¤]

        ## ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸
        [ìƒê´€ê´€ê³„ê°€ ë¹„ì¦ˆë‹ˆìŠ¤ì ìœ¼ë¡œ ì˜ë¯¸í•˜ëŠ” ë°”]

        ## ëª¨ë¸ë§ ì „ëµ
        [ìƒê´€ê´€ê³„ë¥¼ ê³ ë ¤í•œ ëª¨ë¸ë§ ì „ëµ]

        ## íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ ì•„ì´ë””ì–´
        [ìƒê´€ê´€ê³„ë¥¼ í™œìš©í•œ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ ì œì•ˆ]
        """
        
        response = llm.invoke([HumanMessage(content=llm_prompt)])
        llm_insights = response.content
        
        analysis_text += f"\n\n=== LLM ì¶”ê°€ ì¸ì‚¬ì´íŠ¸ ===\n{llm_insights}"
        
    except Exception as e:
        print(f"LLM ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
    
    print("ìƒê´€ê´€ê³„ ë¶„ì„ ì™„ë£Œ")
    
    return {
        **inputs,
        "correlation_analysis": analysis_text
    }


# LangGraph ë…¸ë“œë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í•¨ìˆ˜
correlation_text_agent = RunnableLambda(analyze_correlations)
