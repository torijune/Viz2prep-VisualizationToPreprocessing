"""
ë²”ì£¼í˜• ë°ì´í„° ë¶„ì„ í…ìŠ¤íŠ¸ ì—ì´ì „íŠ¸
unique ê°’, value_counts, ì¹´í…Œê³ ë¦¬ ë¶ˆê· í˜• ë“±ì„ ë¶„ì„í•˜ì—¬ í…ìŠ¤íŠ¸ í˜•íƒœë¡œ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
"""

import pandas as pd
import numpy as np
from typing import Dict, Any
from langchain_core.runnables import RunnableLambda
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage


def analyze_categorical_data(inputs: Dict[str, Any]) -> Dict[str, Any]:
    """
    ë²”ì£¼í˜• ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  í…ìŠ¤íŠ¸ í˜•íƒœë¡œ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    
    Args:
        inputs: DataFrameì´ í¬í•¨ëœ ì…ë ¥ ë”•ì…”ë„ˆë¦¬
        
    Returns:
        ë²”ì£¼í˜• ë°ì´í„° ë¶„ì„ ê²°ê³¼ê°€ í¬í•¨ëœ ë”•ì…”ë„ˆë¦¬
    """
    df = inputs["dataframe"]
    
    # ë²”ì£¼í˜• ì»¬ëŸ¼ ì„ íƒ (object, category íƒ€ì…)
    categorical_columns = df.select_dtypes(include=['object', 'category']).columns.tolist()
    
    if not categorical_columns:
        return {
            **inputs,
            "categorical_analysis": "ë²”ì£¼í˜• ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
        }
    
    # ë¶„ì„ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    analysis_text = "=== ë²”ì£¼í˜• ë°ì´í„° ë¶„ì„ ===\n\n"
    
    for col in categorical_columns:
        analysis_text += f"ğŸ“Š {col} ì»¬ëŸ¼ ë¶„ì„:\n"
        
        # ê¸°ë³¸ ì •ë³´
        unique_count = df[col].nunique()
        total_count = len(df[col])
        missing_count = df[col].isnull().sum()
        missing_percentage = (missing_count / total_count) * 100
        
        analysis_text += f"   - ê³ ìœ ê°’ ê°œìˆ˜: {unique_count}ê°œ\n"
        analysis_text += f"   - ì´ ë°ì´í„° ê°œìˆ˜: {total_count}ê°œ\n"
        analysis_text += f"   - ê²°ì¸¡ê°’: {missing_count}ê°œ ({missing_percentage:.1f}%)\n"
        
        # value_counts ë¶„ì„
        value_counts = df[col].value_counts()
        analysis_text += f"   - ìƒìœ„ 5ê°œ ê°’:\n"
        for i, (value, count) in enumerate(value_counts.head().items()):
            percentage = (count / total_count) * 100
            analysis_text += f"     {i+1}. {value}: {count}ê°œ ({percentage:.1f}%)\n"
        
        # ì¹´í…Œê³ ë¦¬ ë¶ˆê· í˜• ë¶„ì„
        if unique_count > 1:
            # ì—”íŠ¸ë¡œí”¼ ê³„ì‚° (ë¶ˆê· í˜• ì§€í‘œ)
            proportions = value_counts / total_count
            entropy = -np.sum(proportions * np.log2(proportions + 1e-10))
            max_entropy = np.log2(unique_count)
            balance_ratio = entropy / max_entropy if max_entropy > 0 else 0
            
            analysis_text += f"   - ì¹´í…Œê³ ë¦¬ ë¶ˆê· í˜• ë¶„ì„:\n"
            analysis_text += f"     * ì—”íŠ¸ë¡œí”¼: {entropy:.3f}\n"
            analysis_text += f"     * ìµœëŒ€ ì—”íŠ¸ë¡œí”¼: {max_entropy:.3f}\n"
            analysis_text += f"     * ê· í˜• ë¹„ìœ¨: {balance_ratio:.3f}\n"
            
            if balance_ratio > 0.8:
                balance_status = "ê· í˜•ì¡íŒ ë¶„í¬"
            elif balance_ratio > 0.5:
                balance_status = "ë³´í†µ ë¶„í¬"
            else:
                balance_status = "ë¶ˆê· í˜• ë¶„í¬"
            
            analysis_text += f"     * ë¶„í¬ ìƒíƒœ: {balance_status}\n"
        
        # ì¹´ë””ë„ë¦¬í‹° ë¶„ì„
        if unique_count <= 10:
            cardinality_status = "ë‚®ìŒ (10ê°œ ì´í•˜)"
        elif unique_count <= 50:
            cardinality_status = "ë³´í†µ (11-50ê°œ)"
        else:
            cardinality_status = "ë†’ìŒ (50ê°œ ì´ˆê³¼)"
        
        analysis_text += f"   - ì¹´ë””ë„ë¦¬í‹°: {cardinality_status}\n"
        
        # ê²°ì¸¡ê°’ íŒ¨í„´ ë¶„ì„
        if missing_count > 0:
            analysis_text += f"   - ê²°ì¸¡ê°’ íŒ¨í„´: {missing_count}ê°œ ê²°ì¸¡\n"
        
        analysis_text += "\n"
    
    # ì „ì²´ ë²”ì£¼í˜• ë°ì´í„° ìš”ì•½
    analysis_text += "=== ì „ì²´ ë²”ì£¼í˜• ë°ì´í„° ìš”ì•½ ===\n"
    analysis_text += f"- ë²”ì£¼í˜• ì»¬ëŸ¼ ìˆ˜: {len(categorical_columns)}ê°œ\n"
    analysis_text += f"- ì»¬ëŸ¼ ëª©ë¡: {', '.join(categorical_columns)}\n"
    
    # ë²”ì£¼í˜• ë³€ìˆ˜ ê°„ ê´€ê³„ ë¶„ì„ (ë²”ì£¼í˜• ì»¬ëŸ¼ì´ 2ê°œ ì´ìƒì¸ ê²½ìš°)
    if len(categorical_columns) >= 2:
        analysis_text += f"\n=== ë²”ì£¼í˜• ë³€ìˆ˜ ê°„ ê´€ê³„ ë¶„ì„ ===\n"
        
        # ì¹´ì´ì œê³± ê²€ì •ì„ ìœ„í•œ êµì°¨í‘œ ìƒì„±
        for i, col1 in enumerate(categorical_columns):
            for j, col2 in enumerate(categorical_columns[i+1:], i+1):
                cross_table = pd.crosstab(df[col1], df[col2], margins=True)
                analysis_text += f"\n{col1} vs {col2} êµì°¨í‘œ:\n"
                analysis_text += cross_table.to_string()
                analysis_text += "\n"
    
    try:
        # LLMì„ ì‚¬ìš©í•˜ì—¬ ì¶”ê°€ ì¸ì‚¬ì´íŠ¸ ìƒì„±
        llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0.1,
            max_tokens=1000
        )
        
        llm_prompt = f"""
        ë‹¤ìŒì€ ë°ì´í„°ì…‹ì˜ ë²”ì£¼í˜• ë³€ìˆ˜ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤:

        {analysis_text}

        ìœ„ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:

        1. **ì£¼ìš” ë°œê²¬ì‚¬í•­**: ê°€ì¥ ì¤‘ìš”í•œ ë²”ì£¼í˜• ë°ì´í„° íŠ¹ì§•ë“¤ì„ ìš”ì•½
        2. **ë¶ˆê· í˜• ë¶„ì„**: ì¹´í…Œê³ ë¦¬ ë¶ˆê· í˜•ì´ ì‹¬í•œ ë³€ìˆ˜ë“¤ê³¼ ê·¸ ì˜ë¯¸
        3. **ì¸ì½”ë”© ì „ëµ**: ê° ë²”ì£¼í˜• ë³€ìˆ˜ì— ì í•©í•œ ì¸ì½”ë”© ë°©ë²• ì œì•ˆ
        4. **ì „ì²˜ë¦¬ ê¶Œì¥ì‚¬í•­**: ë²”ì£¼í˜• ë³€ìˆ˜ ì „ì²˜ë¦¬ë¥¼ ìœ„í•œ êµ¬ì²´ì ì¸ ë°©ë²• ì œì•ˆ

        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:

        ## ì£¼ìš” ë°œê²¬ì‚¬í•­
        [ê°€ì¥ ì¤‘ìš”í•œ ë²”ì£¼í˜• ë°ì´í„° íŠ¹ì§•ë“¤]

        ## ë¶ˆê· í˜• ë¶„ì„
        [ì¹´í…Œê³ ë¦¬ ë¶ˆê· í˜•ì´ ì‹¬í•œ ë³€ìˆ˜ë“¤ê³¼ ì˜ë¯¸]

        ## ì¸ì½”ë”© ì „ëµ
        [ê° ë²”ì£¼í˜• ë³€ìˆ˜ë³„ ì í•©í•œ ì¸ì½”ë”© ë°©ë²•]

        ## ì „ì²˜ë¦¬ ê¶Œì¥ì‚¬í•­
        [ë²”ì£¼í˜• ë³€ìˆ˜ ì „ì²˜ë¦¬ë¥¼ ìœ„í•œ êµ¬ì²´ì ì¸ ë°©ë²•]
        """
        
        response = llm.invoke([HumanMessage(content=llm_prompt)])
        llm_insights = response.content
        
        analysis_text += f"\n\n=== LLM ì¶”ê°€ ì¸ì‚¬ì´íŠ¸ ===\n{llm_insights}"
        
    except Exception as e:
        print(f"LLM ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
    
    print("ë²”ì£¼í˜• ë°ì´í„° ë¶„ì„ ì™„ë£Œ")
    
    return {
        **inputs,
        "categorical_analysis": analysis_text
    }


# LangGraph ë…¸ë“œë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í•¨ìˆ˜
categorical_text_agent = RunnableLambda(analyze_categorical_data)
