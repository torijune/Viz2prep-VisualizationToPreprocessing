"""
ê²°ì¸¡ì¹˜ ë° ì¤‘ë³µ ë°ì´í„° ë¶„ì„ í…ìŠ¤íŠ¸ ì—ì´ì „íŠ¸
isnull, missing_data_percentage, duplicated ë“±ì„ ë¶„ì„í•˜ì—¬ rawí•œ ê²°ì¸¡ì¹˜ ë° ì¤‘ë³µ ë°ì´í„°ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
"""

import pandas as pd
import numpy as np
from typing import Dict, Any
from langchain_core.runnables import RunnableLambda


def analyze_missing_and_duplicate_data(inputs: Dict[str, Any]) -> Dict[str, Any]:
    """
    ê²°ì¸¡ì¹˜ì™€ ì¤‘ë³µ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  rawí•œ ë°ì´í„°ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    
    Args:
        inputs: DataFrameì´ í¬í•¨ëœ ì…ë ¥ ë”•ì…”ë„ˆë¦¬
        
    Returns:
        ê²°ì¸¡ì¹˜ ë° ì¤‘ë³µ ë°ì´í„° ë¶„ì„ ê²°ê³¼ê°€ í¬í•¨ëœ ë”•ì…”ë„ˆë¦¬
    """
    df = inputs["dataframe"]
    
    # ê²°ì¸¡ì¹˜ ë¶„ì„
    total_missing = df.isnull().sum().sum()
    total_cells = df.size
    total_missing_percentage = (total_missing / total_cells) * 100
    
    # ì»¬ëŸ¼ë³„ ê²°ì¸¡ì¹˜ ë¶„ì„
    missing_by_column = df.isnull().sum()
    missing_percentage_by_column = (missing_by_column / len(df)) * 100
    
    # ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” í–‰ë“¤
    rows_with_missing = df.isnull().any(axis=1).sum()
    rows_with_missing_percentage = (rows_with_missing / len(df)) * 100
    
    # ê²°ì¸¡ì¹˜ íŒ¨í„´ (ì—¬ëŸ¬ ì»¬ëŸ¼ì—ì„œ ë™ì‹œì— ê²°ì¸¡)
    missing_patterns = df.isnull().sum(axis=1).value_counts().sort_index()
    
    # ì¤‘ë³µ ë°ì´í„° ë¶„ì„
    total_duplicates = df.duplicated().sum()
    total_duplicates_percentage = (total_duplicates / len(df)) * 100
    
    # ì¤‘ë³µ íŒ¨í„´ ë¶„ì„
    duplicate_info = {}
    if total_duplicates > 0:
        duplicate_counts = df.duplicated(keep=False).sum()
        duplicate_groups = df[df.duplicated(keep=False)].groupby(df.columns.tolist()).size()
        
        duplicate_info = {
            'duplicate_counts': int(duplicate_counts),
            'duplicate_groups_count': len(duplicate_groups),
            'most_common_duplicate_count': int(duplicate_groups.max()) if len(duplicate_groups) > 0 else 0
        }
    
    # ë°ì´í„° í’ˆì§ˆ í†µê³„
    quality_stats = {
        'total_missing': int(total_missing),
        'total_cells': int(total_cells),
        'total_missing_percentage': float(total_missing_percentage),
        'rows_with_missing': int(rows_with_missing),
        'rows_with_missing_percentage': float(rows_with_missing_percentage),
        'total_duplicates': int(total_duplicates),
        'total_duplicates_percentage': float(total_duplicates_percentage)
    }
    
    print("ê²°ì¸¡ì¹˜ ë° ì¤‘ë³µ ë°ì´í„° ë¶„ì„ ì™„ë£Œ")
    
    # ë¶„ì„ ê²°ê³¼ ë¡œê¹…
    print("\n" + "="*50)
    print("ğŸ“Š [EDA] ê²°ì¸¡ì¹˜ ë° ì¤‘ë³µ ë°ì´í„° ë¶„ì„ ê²°ê³¼")
    print("="*50)
    print(f"ğŸ“ˆ ì „ì²´ ë°ì´í„°: {len(df)}í–‰ x {len(df.columns)}ì—´ = {total_cells}ê°œ ì…€")
    print(f"ğŸ” ê²°ì¸¡ì¹˜:")
    print(f"   - ì „ì²´ ê²°ì¸¡ì¹˜: {total_missing}ê°œ ({total_missing_percentage:.2f}%)")
    print(f"   - ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” í–‰: {rows_with_missing}ê°œ ({rows_with_missing_percentage:.2f}%)")
    
    # ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” ì»¬ëŸ¼ë“¤ë§Œ ì¶œë ¥
    columns_with_missing = missing_by_column[missing_by_column > 0]
    if len(columns_with_missing) > 0:
        print(f"   - ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” ì»¬ëŸ¼: {len(columns_with_missing)}ê°œ")
        for col, count in columns_with_missing.items():
            percentage = missing_percentage_by_column[col]
            print(f"     * {col}: {count}ê°œ ({percentage:.2f}%)")
    else:
        print(f"   - ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” ì»¬ëŸ¼: ì—†ìŒ")
    
    print(f"ğŸ” ì¤‘ë³µ ë°ì´í„°:")
    print(f"   - ì „ì²´ ì¤‘ë³µ í–‰: {total_duplicates}ê°œ ({total_duplicates_percentage:.2f}%)")
    if total_duplicates > 0:
        print(f"   - ì¤‘ë³µ íŒ¨í„´ì´ ìˆëŠ” í–‰: {duplicate_info['duplicate_counts']}ê°œ")
        print(f"   - ì¤‘ë³µ ê·¸ë£¹ ìˆ˜: {duplicate_info['duplicate_groups_count']}ê°œ")
        print(f"   - ê°€ì¥ ë§ì´ ì¤‘ë³µëœ íŒ¨í„´: {duplicate_info['most_common_duplicate_count']}ë²ˆ")
    
    result = {
        **inputs,
        "missing_duplicate_analysis": {
            "missing_by_column": missing_by_column.to_dict(),
            "missing_percentage_by_column": missing_percentage_by_column.to_dict(),
            "missing_patterns": missing_patterns.to_dict(),
            "duplicate_info": duplicate_info,
            "quality_stats": quality_stats,
            "columns_analyzed": df.columns.tolist()
        }
    }
    
    return result


# LangGraph ë…¸ë“œë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í•¨ìˆ˜
missing_duplicate_text_agent = RunnableLambda(analyze_missing_and_duplicate_data) 