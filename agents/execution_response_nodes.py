#!/usr/bin/env python3
"""
ì‹¤í–‰ ë° ì‘ë‹µ ë…¸ë“œë“¤
ì „ë¬¸ ì½”ë”ë“¤ì´ ìƒì„±í•œ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ê³  ìµœì¢… ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë…¸ë“œë“¤
"""

import os
import sys
from typing import Dict, Any, List
import pandas as pd
import numpy as np
from langchain_core.messages import HumanMessage
from langchain_openai import ChatOpenAI

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from workflow_state import WorkflowState

def executor_node(state: WorkflowState) -> WorkflowState:
    """
    ì½”ë“œ ì‹¤í–‰ ë…¸ë“œ
    
    ğŸ” INPUT STATES:
    - dataframe: ì›ë³¸ ë°ì´í„°í”„ë ˆì„
    - numeric_code: ìˆ˜ì¹˜í˜• ì „ì²˜ë¦¬ ì½”ë“œ (1ìˆœìœ„)
    - category_code: ë²”ì£¼í˜• ì „ì²˜ë¦¬ ì½”ë“œ (2ìˆœìœ„)
    - outlier_code: ì´ìƒì¹˜ ì „ì²˜ë¦¬ ì½”ë“œ (3ìˆœìœ„)
    - nulldata_code: ê²°ì¸¡ê°’ ì „ì²˜ë¦¬ ì½”ë“œ (4ìˆœìœ„)
    - corr_code: ìƒê´€ê´€ê³„ ì „ì²˜ë¦¬ ì½”ë“œ (5ìˆœìœ„)
    
    ğŸ“Š OUTPUT STATES:
    - processed_dataframe: ìµœì¢… ì „ì²˜ë¦¬ëœ ë°ì´í„°í”„ë ˆì„
    - execution_results: ê° ì „ì²˜ë¦¬ ë‹¨ê³„ë³„ ì‹¤í–‰ ê²°ê³¼
    - execution_errors: ì‹¤í–‰ ì¤‘ ë°œìƒí•œ ì˜¤ë¥˜ë“¤
    - needs_debugging: ë””ë²„ê¹…ì´ í•„ìš”í•œì§€ ì—¬ë¶€
    - debug_info: ë””ë²„ê¹…ì„ ìœ„í•œ ì •ë³´
    
    â¡ï¸ NEXT EDGE: responder (ì„±ê³µ ì‹œ) ë˜ëŠ” debug_router (ì˜¤ë¥˜ ì‹œ)
    """
    print("ğŸ”§ [EXEC] ì „ì²˜ë¦¬ ì½”ë“œ ì‹¤í–‰ ì‹œì‘...")
    
    try:
        # ì›ë³¸ ë°ì´í„°í”„ë ˆì„ ë³µì‚¬
        original_df = state["dataframe"]
        current_df = original_df.copy()
        
        # ì‹¤í–‰ ê²°ê³¼ ì¶”ì 
        execution_results = []
        execution_errors = []
        needs_debugging = False
        debug_info = {}
        
        # ì‹¤í–‰ ìˆœì„œ ì •ì˜ (ìš°ì„ ìˆœìœ„ ê¸°ë°˜)
        execution_order = [
            ("nulldata", "nulldata_code", "preprocess_missing_data", "ê²°ì¸¡ê°’ ì²˜ë¦¬"),
            ("outlier", "outlier_code", "preprocess_outliers", "ì´ìƒì¹˜ ì²˜ë¦¬"),
            ("numeric", "numeric_code", "preprocess_numeric_data", "ìˆ˜ì¹˜í˜• ì „ì²˜ë¦¬"),
            ("category", "category_code", "preprocess_categorical_data", "ë²”ì£¼í˜• ì „ì²˜ë¦¬"),
            ("correlation", "corr_code", "preprocess_correlation_features", "ìƒê´€ê´€ê³„ ì „ì²˜ë¦¬")
        ]
        
        print("ğŸ“Š [EXEC] ì „ì²˜ë¦¬ ì „ ë°ì´í„°í”„ë ˆì„ ìƒíƒœ:")
        print(f"   - í¬ê¸°: {current_df.shape}")
        print(f"   - ê²°ì¸¡ê°’: {current_df.isnull().sum().sum()}ê°œ")
        print(f"   - ë°ì´í„° íƒ€ì…: {dict(current_df.dtypes.value_counts())}")
        
        # ìˆ˜ì •ëœ ì½”ë“œê°€ ìˆëŠ”ì§€ í™•ì¸
        fixed_code = state.get("fixed_preprocessing_code", "")
        if fixed_code and fixed_code.strip():
            print("ğŸ”§ [EXEC] ìˆ˜ì •ëœ ì½”ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì¬ì‹¤í–‰...")
            # ìˆ˜ì •ëœ ì½”ë“œë¥¼ ëª¨ë“  ë‹¨ê³„ì— ì ìš©
            for step, code_key, function_name, description in execution_order:
                state[code_key] = fixed_code
            # ë””ë²„ê¹… ì™„ë£Œ í›„ì—ëŠ” ìˆ˜ì •ëœ ì½”ë“œë¥¼ ì´ˆê¸°í™”í•˜ì—¬ ë¬´í•œ ë£¨í”„ ë°©ì§€
            state["fixed_preprocessing_code"] = ""
            # ë””ë²„ê¹… ìƒíƒœë„ ì´ˆê¸°í™”
            state["debug_status"] = ""
            state["debug_message"] = ""
        
        # ê° ì½”ë“œë¥¼ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰
        for step, code_key, function_name, description in execution_order:
            print(f"\nğŸ”„ [EXEC] {description} ì‹¤í–‰ ì¤‘...")
            
            code = state.get(code_key, "")
            if not code or code.strip() == "":
                print(f"â­ï¸  [EXEC] {description} ì½”ë“œê°€ ì—†ì–´ì„œ ê±´ë„ˆëœ€")
                continue
            
            try:
                # ì „ì²˜ë¦¬ ì „ ìƒíƒœ ê¸°ë¡
                before_shape = current_df.shape
                before_nulls = current_df.isnull().sum().sum()
                
                # ë¡œì»¬ í™˜ê²½ì—ì„œ ì½”ë“œ ì‹¤í–‰
                local_vars = {
                    'df': current_df.copy(),
                    'pd': pd,
                    'np': np,
                    'current_df': current_df.copy()
                }
                
                # í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ ë¯¸ë¦¬ import
                exec_globals = {
                    '__builtins__': __builtins__,
                    'pd': pd,
                    'np': np,
                    'pandas': pd,
                    'numpy': np
                }
                
                # sklearn ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ import
                try:
                    from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, LabelEncoder
                    from sklearn.ensemble import IsolationForest
                    from sklearn.feature_selection import VarianceThreshold
                    exec_globals.update({
                        'StandardScaler': StandardScaler,
                        'MinMaxScaler': MinMaxScaler,
                        'RobustScaler': RobustScaler,
                        'LabelEncoder': LabelEncoder,
                        'IsolationForest': IsolationForest,
                        'VarianceThreshold': VarianceThreshold
                    })
                except ImportError as e:
                    print(f"âš ï¸  [EXEC] sklearn import ê²½ê³ : {e}")
                
                # ì½”ë“œ ì‹¤í–‰
                exec(code, exec_globals, local_vars)
                
                # í•¨ìˆ˜ ì‹¤í–‰
                if function_name in local_vars:
                    try:
                        processed_df = local_vars[function_name](current_df)
                        if processed_df is not None:
                            current_df = processed_df
                        else:
                            print(f"âš ï¸  [EXEC] {function_name} í•¨ìˆ˜ê°€ Noneì„ ë°˜í™˜í•¨")
                            continue
                    except Exception as e:
                        print(f"âš ï¸  [EXEC] {function_name} í•¨ìˆ˜ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
                        continue
                else:
                    # í•¨ìˆ˜ê°€ ì •ì˜ë˜ì§€ ì•Šì€ ê²½ìš°, df ë³€ìˆ˜ ì‚¬ìš©
                    if 'df' in local_vars and local_vars['df'] is not None:
                        current_df = local_vars['df']
                    else:
                        print(f"âš ï¸  [EXEC] {function_name} í•¨ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                        continue
                
                # ì „ì²˜ë¦¬ í›„ ìƒíƒœ ê¸°ë¡
                after_shape = current_df.shape
                after_nulls = current_df.isnull().sum().sum()
                
                # ì‹¤í–‰ ê²°ê³¼ ì €ì¥
                step_result = {
                    "step": step,
                    "description": description,
                    "before_shape": before_shape,
                    "after_shape": after_shape,
                    "before_nulls": before_nulls,
                    "after_nulls": after_nulls,
                    "shape_change": f"{before_shape} â†’ {after_shape}",
                    "nulls_change": f"{before_nulls} â†’ {after_nulls}",
                    "status": "success"
                }
                execution_results.append(step_result)
                
                print(f"âœ… [EXEC] {description} ì™„ë£Œ:")
                print(f"   - í¬ê¸° ë³€í™”: {before_shape} â†’ {after_shape}")
                print(f"   - ê²°ì¸¡ê°’ ë³€í™”: {before_nulls} â†’ {after_nulls}")
                
            except Exception as e:
                error_msg = f"{description} ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}"
                execution_errors.append(error_msg)
                print(f"âŒ [EXEC] {error_msg}")
                
                # ë””ë²„ê¹…ì´ í•„ìš”í•œ ê²½ìš° ì •ë³´ ìˆ˜ì§‘
                needs_debugging = True
                debug_info = {
                    "error_message": error_msg,
                    "original_code": code,
                    "dataframe_info": {
                        "shape": current_df.shape,
                        "columns": list(current_df.columns),
                        "dtypes": dict(current_df.dtypes),
                        "null_counts": dict(current_df.isnull().sum())
                    },
                    "preprocessing_plan": {
                        "step": step,
                        "description": description,
                        "function_name": function_name
                    }
                }
                
                # ì‹¤í–‰ ì‹¤íŒ¨ ê²°ê³¼ ì €ì¥
                step_result = {
                    "step": step,
                    "description": description,
                    "before_shape": before_shape,
                    "after_shape": before_shape,  # ë³€í™” ì—†ìŒ
                    "before_nulls": before_nulls,
                    "after_nulls": before_nulls,  # ë³€í™” ì—†ìŒ
                    "shape_change": "ë³€í™” ì—†ìŒ (ì˜¤ë¥˜)",
                    "nulls_change": "ë³€í™” ì—†ìŒ (ì˜¤ë¥˜)",
                    "status": "error",
                    "error": str(e)
                }
                execution_results.append(step_result)
                
                # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë””ë²„ê¹… ì •ë³´ ìˆ˜ì§‘ (ê³„ì† ì§„í–‰)
                print(f"âš ï¸  [EXEC] {description} ì˜¤ë¥˜ ë°œìƒ, ê³„ì† ì§„í–‰...")
        
        # ëª¨ë“  ì „ì²˜ë¦¬ ë‹¨ê³„ ì™„ë£Œ í›„ ì˜¤ë¥˜ í™•ì¸
        successful_steps = [r for r in execution_results if r.get("status") == "success"]
        failed_steps = [r for r in execution_results if r.get("status") == "error"]
        
        print(f"\nğŸ“Š [EXEC] ì „ì²˜ë¦¬ ì™„ë£Œ ìš”ì•½:")
        print(f"   - ì„±ê³µí•œ ë‹¨ê³„: {len(successful_steps)}/{len(execution_results)}ê°œ")
        print(f"   - ì‹¤íŒ¨í•œ ë‹¨ê³„: {len(failed_steps)}ê°œ")
        
        if failed_steps:
            print(f"ğŸ”§ [EXEC] {len(failed_steps)}ê°œ ë‹¨ê³„ì—ì„œ ì˜¤ë¥˜ ë°œìƒ. Debug Agentë¡œ ì „ë‹¬...")
            # ê°€ì¥ ìµœê·¼ ì˜¤ë¥˜ ì •ë³´ ì‚¬ìš©
            latest_error = failed_steps[-1]
            return {
                **state,
                "processed_dataframe": current_df,
                "execution_results": execution_results,
                "execution_errors": execution_errors,
                "error_message": latest_error.get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜"),
                "preprocessing_code": state.get("numeric_code", "") + "\n" + state.get("category_code", "") + "\n" + state.get("outlier_code", "") + "\n" + state.get("nulldata_code", "") + "\n" + state.get("corr_code", ""),
                "execution_result": {"status": "error"}
            }
        else:
            print(f"\nğŸ‰ [EXEC] ì „ì²´ ì „ì²˜ë¦¬ ì™„ë£Œ!")
            print(f"ğŸ“Š [EXEC] ìµœì¢… ë°ì´í„°í”„ë ˆì„ ìƒíƒœ:")
            print(f"   - ìµœì¢… í¬ê¸°: {current_df.shape}")
            print(f"   - ìµœì¢… ê²°ì¸¡ê°’: {current_df.isnull().sum().sum()}ê°œ")
            print(f"   - ì„±ê³µí•œ ë‹¨ê³„: {len(successful_steps)}/{len(execution_results)}ê°œ")
            
            return {
                **state,
                "processed_dataframe": current_df,
                "execution_results": execution_results,
                "execution_errors": execution_errors,
                "execution_result": {"status": "success"}
            }
        
    except Exception as e:
        print(f"âŒ [EXEC] ì „ì²´ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        return {
            **state,
            "processed_dataframe": original_df,  # ì›ë³¸ ë°˜í™˜
            "execution_results": [{
                "step": "ì „ì²´",
                "description": "ì „ì²´ ì‹¤í–‰",
                "status": "error",
                "error": str(e)
            }],
            "execution_errors": [f"ì „ì²´ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}"],
            "error_message": f"ì „ì²´ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}",
            "preprocessing_code": "ì „ì²´ ì‹¤í–‰ ì‹¤íŒ¨",
            "execution_result": {"status": "error"}
        }


def responder_node(state: WorkflowState) -> WorkflowState:
    """
    ìµœì¢… ì‘ë‹µ ë…¸ë“œ - ì „ì²˜ë¦¬ëœ ë°ì´í„°í”„ë ˆì„ ë°˜í™˜
    
    ğŸ” INPUT STATES:
    - query: ì‚¬ìš©ì ìš”ì²­
    - processed_dataframe: ìµœì¢… ì „ì²˜ë¦¬ëœ ë°ì´í„°í”„ë ˆì„
    - execution_results: ê° ì „ì²˜ë¦¬ ë‹¨ê³„ë³„ ì‹¤í–‰ ê²°ê³¼
    - execution_errors: ì‹¤í–‰ ì¤‘ ë°œìƒí•œ ì˜¤ë¥˜ë“¤
    
    ğŸ“Š OUTPUT STATES:
    - final_response: ì „ì²˜ë¦¬ëœ ë°ì´í„°í”„ë ˆì„ê³¼ ê¸°ë³¸ ì •ë³´
    
    â¡ï¸ NEXT EDGE: END
    """
    print("ğŸ“ [RESPONSE] ìµœì¢… ì‘ë‹µ ìƒì„± ì¤‘...")
    
    try:
        query = state.get("query", "")
        processed_df = state.get("processed_dataframe")
        execution_results = state.get("execution_results", [])
        execution_errors = state.get("execution_errors", [])
        original_df = state.get("dataframe")
        
        # ë””ë²„ê¹… ì •ë³´ í™•ì¸
        debug_status = state.get("debug_status", "")
        debug_message = state.get("debug_message", "")
        fixed_preprocessing_code = state.get("fixed_preprocessing_code", "")
        debug_analysis = state.get("debug_analysis", {})
        
        # ì‹¤í–‰ ê²°ê³¼ ìš”ì•½
        successful_steps = [r for r in execution_results if r.get("status") == "success"]
        failed_steps = [r for r in execution_results if r.get("status") == "error"]
        
        # ë°ì´í„°í”„ë ˆì„ ë³€í™” ìš”ì•½
        original_shape = original_df.shape if original_df is not None else (0, 0)
        final_shape = processed_df.shape if processed_df is not None else (0, 0)
        original_nulls = original_df.isnull().sum().sum() if original_df is not None else 0
        final_nulls = processed_df.isnull().sum().sum() if processed_df is not None else 0
        
        # ì „ì²˜ë¦¬ ìš”ì•½ ì •ë³´ ìƒì„±
        preprocessing_summary = {
            "user_query": query,
            "original_data_info": {
                "shape": original_shape,
                "missing_values": original_nulls,
                "data_types": dict(original_df.dtypes.value_counts()) if original_df is not None else {}
            },
            "final_data_info": {
                "shape": final_shape,
                "missing_values": final_nulls,
                "data_types": dict(processed_df.dtypes.value_counts()) if processed_df is not None else {}
            },
            "processing_steps": {
                "total_steps": len(execution_results),
                "successful_steps": len(successful_steps),
                "failed_steps": len(failed_steps),
                "success_rate": len(successful_steps) / len(execution_results) * 100 if execution_results else 0
            },
            "data_quality_improvements": {
                "missing_values_removed": original_nulls - final_nulls,
                "shape_change": f"{original_shape} â†’ {final_shape}",
                "data_completeness": (1 - final_nulls / (final_shape[0] * final_shape[1])) * 100 if final_shape[0] * final_shape[1] > 0 else 0
            },
            "execution_details": execution_results,
            "errors": execution_errors,
            "debug_info": {
                "debug_status": debug_status,
                "debug_message": debug_message,
                "debug_analysis": debug_analysis,
                "has_fixed_code": bool(fixed_preprocessing_code)
            }
        }
        
        # ê°„ë‹¨í•œ ì„±ê³µ ë©”ì‹œì§€ ìƒì„±
        success_message = f"""
âœ… ì „ì²˜ë¦¬ ì™„ë£Œ!

ğŸ“Š ë°ì´í„° ì •ë³´:
- ì›ë³¸: {original_shape[0]}í–‰ x {original_shape[1]}ì—´
- ìµœì¢…: {final_shape[0]}í–‰ x {final_shape[1]}ì—´
- ì„±ê³µë¥ : {preprocessing_summary['processing_steps']['success_rate']:.1f}%
- ê²°ì¸¡ê°’ ë³€í™”: {original_nulls} â†’ {final_nulls}

ğŸ¯ ì „ì²˜ë¦¬ëœ ë°ì´í„°í”„ë ˆì„ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. ML í•™ìŠµì— ë°”ë¡œ ì‚¬ìš©í•˜ì„¸ìš”!
"""
        
        print("âœ… [RESPONSE] ìµœì¢… ì‘ë‹µ ìƒì„± ì™„ë£Œ")
        print(f"ğŸ“Š [RESPONSE] ìš”ì•½:")
        print(f"   - ì„±ê³µë¥ : {preprocessing_summary['processing_steps']['success_rate']:.1f}%")
        print(f"   - ë°ì´í„° ì™„ì „ì„±: {preprocessing_summary['data_quality_improvements']['data_completeness']:.1f}%")
        print(f"   - ì œê±°ëœ ê²°ì¸¡ê°’: {preprocessing_summary['data_quality_improvements']['missing_values_removed']}ê°œ")
        
        return {
            **state,
            "final_response": success_message,
            "preprocessing_summary": preprocessing_summary
        }
        
    except Exception as e:
        print(f"âŒ [RESPONSE] ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
        
        # ê¸°ë³¸ ì‘ë‹µ ìƒì„±
        basic_summary = {
            "user_query": query,
            "status": "error",
            "error_message": str(e),
            "processing_steps": {"total_steps": 0, "successful_steps": 0, "failed_steps": 0}
        }
        
        error_message = f"""
âš ï¸ ì „ì²˜ë¦¬ ì™„ë£Œ (ì˜¤ë¥˜ ë°œìƒ)

ğŸ“Š ë°ì´í„° ì •ë³´:
- ì›ë³¸: {original_df.shape if original_df is not None else (0, 0)}
- ìµœì¢…: {processed_df.shape if processed_df is not None else (0, 0)}

âŒ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}

ğŸ¯ ì „ì²˜ë¦¬ëœ ë°ì´í„°í”„ë ˆì„ì€ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.
"""
        
        return {
            **state,
            "final_response": error_message,
            "preprocessing_summary": basic_summary
        } 