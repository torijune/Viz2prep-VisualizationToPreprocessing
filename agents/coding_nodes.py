#!/usr/bin/env python3
"""
ì „ë¬¸ ì½”ë” ë…¸ë“œë“¤
ê° ë„ë©”ì¸ë³„ë¡œ ì „ë¬¸í™”ëœ ì „ì²˜ë¦¬ ì½”ë“œë¥¼ ìƒì„±í•˜ëŠ” ë…¸ë“œë“¤
"""

import os
import sys
from typing import Dict, Any
import json
from langchain_core.messages import HumanMessage
from langchain_openai import ChatOpenAI

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Knowledge Base ì—ì´ì „íŠ¸ import
from KB_rag_agents.KB_rag_agent import KnowledgeBaseRAGAgent

from workflow_state import WorkflowState

def numeric_coder_node(state: WorkflowState) -> WorkflowState:
    """
    ìˆ˜ì¹˜í˜• ì „ì²˜ë¦¬ ì½”ë” ë…¸ë“œ
    
    ğŸ” INPUT STATES:
    - numeric_plan: ìˆ˜ì¹˜í˜• ì „ì²˜ë¦¬ ê³„íš
    - numeric_eda_result: ìˆ˜ì¹˜í˜• ë³€ìˆ˜ EDA ê²°ê³¼
    
    ğŸ“Š OUTPUT STATES:
    - numeric_code: ìˆ˜ì¹˜í˜• ì „ì²˜ë¦¬ ì½”ë“œ
    
    â¡ï¸ NEXT EDGE: executor (1ë²ˆì§¸ ìˆœì„œ)
    """
    print("ğŸ’» [CODE] ìˆ˜ì¹˜í˜• ì „ì²˜ë¦¬ ì½”ë“œ ìƒì„± ì¤‘...")
    
    try:
        numeric_plan = state.get("numeric_plan", {})
        numeric_eda = state.get("numeric_eda_result", {})
        dataframe = state.get("dataframe")
        
        # ì‹¤ì œ ë°ì´í„°í”„ë ˆì„ì˜ ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ê°€ì ¸ì˜¤ê¸°
        actual_numeric_columns = dataframe.select_dtypes(include=['number']).columns.tolist()
        
        # Knowledge Baseì—ì„œ ê´€ë ¨ ì½”ë“œ ê²€ìƒ‰
        kb_agent = KnowledgeBaseRAGAgent()
        kb_query = f"ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ì „ì²˜ë¦¬ {' '.join(numeric_plan.get('techniques', []))}"
        kb_result = kb_agent.search_techniques(kb_query, numeric_plan.get('techniques', []))
        
        # LLMì„ ì‚¬ìš©í•˜ì—¬ ì½”ë“œ ìƒì„±
        llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.1, max_tokens=1500)
        
        prompt = f"""
ë‹¹ì‹ ì€ ìˆ˜ì¹˜í˜• ë°ì´í„° ì „ì²˜ë¦¬ ì½”ë“œ ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ ê³„íšê³¼ EDA ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•œ Python ì½”ë“œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

=== ì‹¤ì œ ë°ì´í„°í”„ë ˆì„ ì •ë³´ ===
- ì „ì²´ ì»¬ëŸ¼: {list(dataframe.columns)}
- ìˆ˜ì¹˜í˜• ì»¬ëŸ¼: {actual_numeric_columns}
- ë°ì´í„°í”„ë ˆì„ í¬ê¸°: {dataframe.shape}

=== ìˆ˜ì¹˜í˜• ì „ì²˜ë¦¬ ê³„íš ===
ê¸°ë²•: {numeric_plan.get('techniques', [])}
ê·¼ê±°: {numeric_plan.get('rationale', '')}

=== EDA ê²°ê³¼ ===
ë¶„ì„ëœ ì»¬ëŸ¼: {numeric_eda.get('columns_analyzed', [])}
í†µê³„: {numeric_eda.get('statistics', {})}

=== Knowledge Base ì°¸ê³  ===
{kb_result}

=== ìš”êµ¬ì‚¬í•­ ===
1. í•¨ìˆ˜ëª…: def preprocess_numeric_data(df):
2. ì…ë ¥: pandas DataFrame (ì‚¬ìš©ìê°€ ì œê³µí•œ ì‹¤ì œ ë°ì´í„°í”„ë ˆì„)
3. ì¶œë ¥: ì „ì²˜ë¦¬ëœ pandas DataFrame
4. ë°˜ë“œì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œì—¬ì•¼ í•¨
5. í•„ìš”í•œ import êµ¬ë¬¸ í¬í•¨
6. ì˜¤ë¥˜ ì²˜ë¦¬ í¬í•¨
7. ì‹¤ì œ ë°ì´í„°í”„ë ˆì„ì˜ ì»¬ëŸ¼ëª…ì„ ì‚¬ìš©í•˜ì„¸ìš”: {actual_numeric_columns}
8. âš ï¸ ì¤‘ìš”: ìƒˆë¡œìš´ ë°ì´í„°í”„ë ˆì„ì„ ì •ì˜í•˜ì§€ ë§ˆì„¸ìš” (df = pd.DataFrame(...) ê¸ˆì§€)
9. âš ï¸ ì¤‘ìš”: ì…ë ¥ë°›ì€ dfë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ ì „ì²˜ë¦¬í•˜ì„¸ìš”
10. âš ï¸ ì¤‘ìš”: Iris ë°ì´í„°ì˜ ì‹¤ì œ ì»¬ëŸ¼ëª… ì‚¬ìš©: {list(dataframe.columns)}
11. âš ï¸ ì¤‘ìš”: í•„ìš”í•œ ëª¨ë“  import êµ¬ë¬¸ì„ í¬í•¨í•˜ì„¸ìš” (pandas, numpy, sklearn, scipy ë“±)

Python ì½”ë“œë§Œ ìƒì„±í•´ì£¼ì„¸ìš” (ì£¼ì„ í¬í•¨):
"""

        response = llm.invoke([HumanMessage(content=prompt)])
        generated_code = response.content
        
        # ì½”ë“œê°€ ```pythonìœ¼ë¡œ ë‘˜ëŸ¬ì‹¸ì—¬ ìˆë‹¤ë©´ ì œê±°
        if "```python" in generated_code:
            generated_code = generated_code.split("```python")[1].split("```")[0].strip()
        elif "```" in generated_code:
            generated_code = generated_code.split("```")[1].strip()
        
        print(f"âœ… [CODE] ìˆ˜ì¹˜í˜• ì½”ë“œ ìƒì„± ì™„ë£Œ - {len(numeric_plan.get('techniques', []))}ê°œ ê¸°ë²•")
        print("ğŸ“ [CODE] ìƒì„±ëœ ìˆ˜ì¹˜í˜• ì „ì²˜ë¦¬ ì½”ë“œ:")
        print("=" * 50)
        print(generated_code)
        print("=" * 50)
        
        return {
            **state,
            "numeric_code": generated_code
        }
        
    except Exception as e:
        print(f"âŒ [CODE] ìˆ˜ì¹˜í˜• ì½”ë“œ ìƒì„± ì˜¤ë¥˜: {e}")
        # ê¸°ë³¸ ì½”ë“œ ì œê³µ
        default_code = """
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from scipy import stats
from scipy.stats import mstats

def preprocess_numeric_data(df):
    \"\"\"ìˆ˜ì¹˜í˜• ë°ì´í„° ì „ì²˜ë¦¬ (ê¸°ë³¸)\"\"\"
    try:
        df_processed = df.copy()
        numeric_columns = df_processed.select_dtypes(include=[np.number]).columns
        
        if len(numeric_columns) > 0:
            scaler = StandardScaler()
            df_processed[numeric_columns] = scaler.fit_transform(df_processed[numeric_columns])
        
        return df_processed
    except Exception as e:
        print(f"ìˆ˜ì¹˜í˜• ì „ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return df
"""
        return {
            **state,
            "numeric_code": default_code
        }


def category_coder_node(state: WorkflowState) -> WorkflowState:
    """
    ë²”ì£¼í˜• ì „ì²˜ë¦¬ ì½”ë” ë…¸ë“œ
    
    ğŸ” INPUT STATES:
    - category_plan: ë²”ì£¼í˜• ì „ì²˜ë¦¬ ê³„íš
    - category_eda_result: ë²”ì£¼í˜• ë³€ìˆ˜ EDA ê²°ê³¼
    
    ğŸ“Š OUTPUT STATES:
    - category_code: ë²”ì£¼í˜• ì „ì²˜ë¦¬ ì½”ë“œ
    
    â¡ï¸ NEXT EDGE: executor (2ë²ˆì§¸ ìˆœì„œ)
    """
    print("ğŸ’» [CODE] ë²”ì£¼í˜• ì „ì²˜ë¦¬ ì½”ë“œ ìƒì„± ì¤‘...")
    
    try:
        category_plan = state.get("category_plan", {})
        category_eda = state.get("category_eda_result", {})
        dataframe = state.get("dataframe")
        
        # ì‹¤ì œ ë°ì´í„°í”„ë ˆì„ì˜ ë²”ì£¼í˜• ì»¬ëŸ¼ ê°€ì ¸ì˜¤ê¸°
        actual_categorical_columns = dataframe.select_dtypes(include=['object', 'category']).columns.tolist()
        
        # Knowledge Baseì—ì„œ ê´€ë ¨ ì½”ë“œ ê²€ìƒ‰
        kb_agent = KnowledgeBaseRAGAgent()
        kb_query = f"ë²”ì£¼í˜• ë³€ìˆ˜ ì „ì²˜ë¦¬ {' '.join(category_plan.get('techniques', []))}"
        kb_result = kb_agent.search_techniques(kb_query, category_plan.get('techniques', []))
        
        llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.1, max_tokens=1500)
        
        prompt = f"""
ë‹¹ì‹ ì€ ë²”ì£¼í˜• ë°ì´í„° ì „ì²˜ë¦¬ ì½”ë“œ ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ ê³„íšê³¼ EDA ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•œ Python ì½”ë“œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

=== ì‹¤ì œ ë°ì´í„°í”„ë ˆì„ ì •ë³´ ===
- ì „ì²´ ì»¬ëŸ¼: {list(dataframe.columns)}
- ë²”ì£¼í˜• ì»¬ëŸ¼: {actual_categorical_columns}
- ë°ì´í„°í”„ë ˆì„ í¬ê¸°: {dataframe.shape}

=== ë²”ì£¼í˜• ì „ì²˜ë¦¬ ê³„íš ===
ê¸°ë²•: {category_plan.get('techniques', [])}
ê·¼ê±°: {category_plan.get('rationale', '')}

=== EDA ê²°ê³¼ ===
ë¶„ì„ëœ ì»¬ëŸ¼: {category_eda.get('columns_analyzed', [])}
ë²”ì£¼í˜• ìš”ì•½: {category_eda.get('categorical_summary', {})}

=== Knowledge Base ì°¸ê³  ===
{kb_result}

=== ìš”êµ¬ì‚¬í•­ ===
1. í•¨ìˆ˜ëª…: def preprocess_categorical_data(df):
2. ì…ë ¥: pandas DataFrame (ì‚¬ìš©ìê°€ ì œê³µí•œ ì‹¤ì œ ë°ì´í„°í”„ë ˆì„)
3. ì¶œë ¥: ì „ì²˜ë¦¬ëœ pandas DataFrame
4. ë°˜ë“œì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œì—¬ì•¼ í•¨
5. í•„ìš”í•œ import êµ¬ë¬¸ í¬í•¨
6. ì˜¤ë¥˜ ì²˜ë¦¬ í¬í•¨
7. ì‹¤ì œ ë°ì´í„°í”„ë ˆì„ì˜ ì»¬ëŸ¼ëª…ì„ ì‚¬ìš©í•˜ì„¸ìš”: {actual_categorical_columns}
8. âš ï¸ ì¤‘ìš”: ìƒˆë¡œìš´ ë°ì´í„°í”„ë ˆì„ì„ ì •ì˜í•˜ì§€ ë§ˆì„¸ìš” (df = pd.DataFrame(...) ê¸ˆì§€)
9. âš ï¸ ì¤‘ìš”: ì…ë ¥ë°›ì€ dfë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ ì „ì²˜ë¦¬í•˜ì„¸ìš”
10. âš ï¸ ì¤‘ìš”: Iris ë°ì´í„°ì˜ ì‹¤ì œ ì»¬ëŸ¼ëª… ì‚¬ìš©: {list(dataframe.columns)}
11. âš ï¸ ì¤‘ìš”: ë²”ì£¼í˜• ë³€ìˆ˜ëŠ” ì›í•« ì¸ì½”ë”©(pd.get_dummies)ì„ ì‚¬ìš©í•˜ì„¸ìš”. Label Encoding ëŒ€ì‹  ì›í•« ì¸ì½”ë”©ì„ ì‚¬ìš©í•˜ì„¸ìš”.
12. âš ï¸ ì¤‘ìš”: ì›í•« ì¸ì½”ë”© ì‹œ dtype=intë¥¼ ì‚¬ìš©í•˜ì—¬ 0/1 ê°’ìœ¼ë¡œ ë³€í™˜í•˜ì„¸ìš”.
13. âš ï¸ ì¤‘ìš”: drop_first=Falseë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  ì¹´í…Œê³ ë¦¬ë¥¼ ìœ ì§€í•˜ì„¸ìš”.

Python ì½”ë“œë§Œ ìƒì„±í•´ì£¼ì„¸ìš” (ì£¼ì„ í¬í•¨):
"""

        response = llm.invoke([HumanMessage(content=prompt)])
        generated_code = response.content
        
        if "```python" in generated_code:
            generated_code = generated_code.split("```python")[1].split("```")[0].strip()
        elif "```" in generated_code:
            generated_code = generated_code.split("```")[1].strip()
        
        print(f"âœ… [CODE] ë²”ì£¼í˜• ì½”ë“œ ìƒì„± ì™„ë£Œ - {len(category_plan.get('techniques', []))}ê°œ ê¸°ë²•")
        print("ğŸ“ [CODE] ìƒì„±ëœ ë²”ì£¼í˜• ì „ì²˜ë¦¬ ì½”ë“œ:")
        print("=" * 50)
        print(generated_code)
        print("=" * 50)
        
        return {
            **state,
            "category_code": generated_code
        }
        
    except Exception as e:
        print(f"âŒ [CODE] ë²”ì£¼í˜• ì½”ë“œ ìƒì„± ì˜¤ë¥˜: {e}")
        default_code = """
import pandas as pd

def preprocess_categorical_data(df):
    \"\"\"ë²”ì£¼í˜• ë°ì´í„° ì „ì²˜ë¦¬ (ê¸°ë³¸ - ì›í•« ì¸ì½”ë”©)\"\"\"
    try:
        df_processed = df.copy()
        categorical_columns = df_processed.select_dtypes(include=['object']).columns
        
        for col in categorical_columns:
            if df_processed[col].nunique() <= 10:
                # ì›í•« ì¸ì½”ë”© ì‚¬ìš© (int íƒ€ì…ìœ¼ë¡œ ë³€í™˜, ëª¨ë“  ì¹´í…Œê³ ë¦¬ ìœ ì§€)
                df_processed = pd.get_dummies(df_processed, columns=[col], drop_first=False, dtype=int)
            else:
                # ì›í•« ì¸ì½”ë”© (ìƒìœ„ 5ê°œ ì¹´í…Œê³ ë¦¬ë§Œ)
                top_categories = df_processed[col].value_counts().head(5).index
                for cat in top_categories:
                    df_processed[f'{col}_{cat}'] = (df_processed[col] == cat).astype(int)
                df_processed.drop(col, axis=1, inplace=True)
        
        return df_processed
    except Exception as e:
        print(f"ë²”ì£¼í˜• ì „ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return df
"""
        return {
            **state,
            "category_code": default_code
        }


def outlier_coder_node(state: WorkflowState) -> WorkflowState:
    """
    ì´ìƒì¹˜ ì „ì²˜ë¦¬ ì½”ë” ë…¸ë“œ
    
    ğŸ” INPUT STATES:
    - outlier_plan: ì´ìƒì¹˜ ì „ì²˜ë¦¬ ê³„íš
    - outlier_eda_result: ì´ìƒì¹˜ EDA ê²°ê³¼
    
    ğŸ“Š OUTPUT STATES:
    - outlier_code: ì´ìƒì¹˜ ì „ì²˜ë¦¬ ì½”ë“œ
    
    â¡ï¸ NEXT EDGE: executor (3ë²ˆì§¸ ìˆœì„œ)
    """
    print("ğŸ’» [CODE] ì´ìƒì¹˜ ì „ì²˜ë¦¬ ì½”ë“œ ìƒì„± ì¤‘...")
    
    try:
        outlier_plan = state.get("outlier_plan", {})
        outlier_eda = state.get("outlier_eda_result", {})
        dataframe = state.get("dataframe")
        
        # ì‹¤ì œ ë°ì´í„°í”„ë ˆì„ì˜ ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ê°€ì ¸ì˜¤ê¸° (ì´ìƒì¹˜ëŠ” ìˆ˜ì¹˜í˜•ì—ë§Œ ì ìš©)
        actual_numeric_columns = dataframe.select_dtypes(include=['number']).columns.tolist()
        
        kb_agent = KnowledgeBaseRAGAgent()
        kb_query = f"ì´ìƒì¹˜ ì²˜ë¦¬ {' '.join(outlier_plan.get('techniques', []))}"
        kb_result = kb_agent.search_techniques(kb_query, outlier_plan.get('techniques', []))
        
        llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.1, max_tokens=1500)
        
        prompt = f"""
ë‹¹ì‹ ì€ ì´ìƒì¹˜ ì²˜ë¦¬ ì½”ë“œ ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ ê³„íšê³¼ EDA ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•œ Python ì½”ë“œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

=== ì‹¤ì œ ë°ì´í„°í”„ë ˆì„ ì •ë³´ ===
- ì „ì²´ ì»¬ëŸ¼: {list(dataframe.columns)}
- ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ (ì´ìƒì¹˜ ì²˜ë¦¬ ëŒ€ìƒ): {actual_numeric_columns}
- ë°ì´í„°í”„ë ˆì„ í¬ê¸°: {dataframe.shape}

=== ì´ìƒì¹˜ ì „ì²˜ë¦¬ ê³„íš ===
ê¸°ë²•: {outlier_plan.get('techniques', [])}
ê·¼ê±°: {outlier_plan.get('rationale', '')}

=== EDA ê²°ê³¼ ===
ë¶„ì„ëœ ì»¬ëŸ¼: {outlier_eda.get('columns_analyzed', [])}
ì´ ì´ìƒì¹˜: {outlier_eda.get('total_outliers', 0)}ê°œ

=== Knowledge Base ì°¸ê³  ===
{kb_result}

=== ìš”êµ¬ì‚¬í•­ ===
1. í•¨ìˆ˜ëª…: def preprocess_outliers(df):
2. ì…ë ¥: pandas DataFrame (ì‚¬ìš©ìê°€ ì œê³µí•œ ì‹¤ì œ ë°ì´í„°í”„ë ˆì„)
3. ì¶œë ¥: ì „ì²˜ë¦¬ëœ pandas DataFrame
4. ë°˜ë“œì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œì—¬ì•¼ í•¨
5. í•„ìš”í•œ import êµ¬ë¬¸ í¬í•¨
6. ì˜¤ë¥˜ ì²˜ë¦¬ í¬í•¨
7. ì‹¤ì œ ë°ì´í„°í”„ë ˆì„ì˜ ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ëª…ì„ ì‚¬ìš©í•˜ì„¸ìš”: {actual_numeric_columns}
8. âš ï¸ ì¤‘ìš”: ìƒˆë¡œìš´ ë°ì´í„°í”„ë ˆì„ì„ ì •ì˜í•˜ì§€ ë§ˆì„¸ìš” (df = pd.DataFrame(...) ê¸ˆì§€)
9. âš ï¸ ì¤‘ìš”: ì…ë ¥ë°›ì€ dfë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ ì „ì²˜ë¦¬í•˜ì„¸ìš”
10. âš ï¸ ì¤‘ìš”: Iris ë°ì´í„°ì˜ ì‹¤ì œ ì»¬ëŸ¼ëª… ì‚¬ìš©: {list(dataframe.columns)}

Python ì½”ë“œë§Œ ìƒì„±í•´ì£¼ì„¸ìš” (ì£¼ì„ í¬í•¨):
"""

        response = llm.invoke([HumanMessage(content=prompt)])
        generated_code = response.content
        
        if "```python" in generated_code:
            generated_code = generated_code.split("```python")[1].split("```")[0].strip()
        elif "```" in generated_code:
            generated_code = generated_code.split("```")[1].strip()
        
        print(f"âœ… [CODE] ì´ìƒì¹˜ ì½”ë“œ ìƒì„± ì™„ë£Œ - {len(outlier_plan.get('techniques', []))}ê°œ ê¸°ë²•")
        print("ğŸ“ [CODE] ìƒì„±ëœ ì´ìƒì¹˜ ì „ì²˜ë¦¬ ì½”ë“œ:")
        print("=" * 50)
        print(generated_code)
        print("=" * 50)
        
        return {
            **state,
            "outlier_code": generated_code
        }
        
    except Exception as e:
        print(f"âŒ [CODE] ì´ìƒì¹˜ ì½”ë“œ ìƒì„± ì˜¤ë¥˜: {e}")
        default_code = """
import pandas as pd
import numpy as np

def preprocess_outliers(df):
    \"\"\"ì´ìƒì¹˜ ì²˜ë¦¬ (ê¸°ë³¸ - IQR ë°©ë²•)\"\"\"
    try:
        df_processed = df.copy()
        numeric_columns = df_processed.select_dtypes(include=[np.number]).columns
        
        for col in numeric_columns:
            Q1 = df_processed[col].quantile(0.25)
            Q3 = df_processed[col].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            
            # ì´ìƒì¹˜ ì œí•œ (capping)
            df_processed[col] = df_processed[col].clip(lower=lower_bound, upper=upper_bound)
        
        return df_processed
    except Exception as e:
        print(f"ì´ìƒì¹˜ ì „ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return df
"""
        return {
            **state,
            "outlier_code": default_code
        }


def nulldata_coder_node(state: WorkflowState) -> WorkflowState:
    """
    ê²°ì¸¡ê°’ ì „ì²˜ë¦¬ ì½”ë” ë…¸ë“œ
    
    ğŸ” INPUT STATES:
    - nulldata_plan: ê²°ì¸¡ê°’ ì „ì²˜ë¦¬ ê³„íš
    - nulldata_eda_result: ê²°ì¸¡ê°’ EDA ê²°ê³¼
    
    ğŸ“Š OUTPUT STATES:
    - nulldata_code: ê²°ì¸¡ê°’ ì „ì²˜ë¦¬ ì½”ë“œ
    
    â¡ï¸ NEXT EDGE: executor (4ë²ˆì§¸ ìˆœì„œ)
    """
    print("ğŸ’» [CODE] ê²°ì¸¡ê°’ ì „ì²˜ë¦¬ ì½”ë“œ ìƒì„± ì¤‘...")
    
    try:
        nulldata_plan = state.get("nulldata_plan", {})
        nulldata_eda = state.get("nulldata_eda_result", {})
        dataframe = state.get("dataframe")
        
        # ì‹¤ì œ ë°ì´í„°í”„ë ˆì„ì˜ ê²°ì¸¡ê°’ì´ ìˆëŠ” ì»¬ëŸ¼ ê°€ì ¸ì˜¤ê¸°
        actual_missing_columns = dataframe.columns[dataframe.isnull().any()].tolist()
        
        kb_agent = KnowledgeBaseRAGAgent()
        kb_query = f"ê²°ì¸¡ê°’ ì²˜ë¦¬ {' '.join(nulldata_plan.get('techniques', []))}"
        kb_result = kb_agent.search_techniques(kb_query, nulldata_plan.get('techniques', []))
        
        llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.1, max_tokens=1500)
        
        prompt = f"""
ë‹¹ì‹ ì€ ê²°ì¸¡ê°’ ì²˜ë¦¬ ì½”ë“œ ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ ê³„íšê³¼ EDA ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•œ Python ì½”ë“œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

=== ì‹¤ì œ ë°ì´í„°í”„ë ˆì„ ì •ë³´ ===
- ì „ì²´ ì»¬ëŸ¼: {list(dataframe.columns)}
- ê²°ì¸¡ê°’ì´ ìˆëŠ” ì»¬ëŸ¼: {actual_missing_columns}
- ë°ì´í„°í”„ë ˆì„ í¬ê¸°: {dataframe.shape}
- ì´ ê²°ì¸¡ê°’ ìˆ˜: {dataframe.isnull().sum().sum()}ê°œ

=== ê²°ì¸¡ê°’ ì „ì²˜ë¦¬ ê³„íš ===
ê¸°ë²•: {nulldata_plan.get('techniques', [])}
ê·¼ê±°: {nulldata_plan.get('rationale', '')}

=== EDA ê²°ê³¼ ===
ê²°ì¸¡ê°’ ì»¬ëŸ¼: {nulldata_eda.get('columns_with_nulls', [])}
ì´ ê²°ì¸¡ê°’: {nulldata_eda.get('total_missing', 0)}ê°œ

=== Knowledge Base ì°¸ê³  ===
{kb_result}

=== ìš”êµ¬ì‚¬í•­ ===
1. í•¨ìˆ˜ëª…: def preprocess_missing_data(df):
2. ì…ë ¥: pandas DataFrame (ì‚¬ìš©ìê°€ ì œê³µí•œ ì‹¤ì œ ë°ì´í„°í”„ë ˆì„)
3. ì¶œë ¥: ì „ì²˜ë¦¬ëœ pandas DataFrame
4. ë°˜ë“œì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œì—¬ì•¼ í•¨
5. í•„ìš”í•œ import êµ¬ë¬¸ í¬í•¨
6. ì˜¤ë¥˜ ì²˜ë¦¬ í¬í•¨
7. ì‹¤ì œ ë°ì´í„°í”„ë ˆì„ì˜ ì»¬ëŸ¼ëª…ì„ ì‚¬ìš©í•˜ì„¸ìš”: {list(dataframe.columns)}
8. âš ï¸ ì¤‘ìš”: ìƒˆë¡œìš´ ë°ì´í„°í”„ë ˆì„ì„ ì •ì˜í•˜ì§€ ë§ˆì„¸ìš” (df = pd.DataFrame(...) ê¸ˆì§€)
9. âš ï¸ ì¤‘ìš”: ì…ë ¥ë°›ì€ dfë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ ì „ì²˜ë¦¬í•˜ì„¸ìš”
10. âš ï¸ ì¤‘ìš”: Iris ë°ì´í„°ì˜ ì‹¤ì œ ì»¬ëŸ¼ëª… ì‚¬ìš©: {list(dataframe.columns)}

Python ì½”ë“œë§Œ ìƒì„±í•´ì£¼ì„¸ìš” (ì£¼ì„ í¬í•¨):
"""

        response = llm.invoke([HumanMessage(content=prompt)])
        generated_code = response.content
        
        if "```python" in generated_code:
            generated_code = generated_code.split("```python")[1].split("```")[0].strip()
        elif "```" in generated_code:
            generated_code = generated_code.split("```")[1].strip()
        
        print(f"âœ… [CODE] ê²°ì¸¡ê°’ ì½”ë“œ ìƒì„± ì™„ë£Œ - {len(nulldata_plan.get('techniques', []))}ê°œ ê¸°ë²•")
        print("ğŸ“ [CODE] ìƒì„±ëœ ê²°ì¸¡ê°’ ì „ì²˜ë¦¬ ì½”ë“œ:")
        print("=" * 50)
        print(generated_code)
        print("=" * 50)
        
        return {
            **state,
            "nulldata_code": generated_code
        }
        
    except Exception as e:
        print(f"âŒ [CODE] ê²°ì¸¡ê°’ ì½”ë“œ ìƒì„± ì˜¤ë¥˜: {e}")
        default_code = """
import pandas as pd
import numpy as np

def preprocess_missing_data(df):
    \"\"\"ê²°ì¸¡ê°’ ì²˜ë¦¬ (ê¸°ë³¸)\"\"\"
    try:
        df_processed = df.copy()
        
        # ê²°ì¸¡ê°’ì´ ìˆëŠ” ì»¬ëŸ¼ë“¤ í™•ì¸
        missing_columns = df_processed.columns[df_processed.isnull().any()].tolist()
        
        if len(missing_columns) == 0:
            print("ê²°ì¸¡ê°’ì´ ì—†ìŠµë‹ˆë‹¤.")
            return df_processed
        
        print(f"ê²°ì¸¡ê°’ ì²˜ë¦¬ ì¤‘: {len(missing_columns)}ê°œ ì»¬ëŸ¼")
        
        for col in missing_columns:
            missing_count = df_processed[col].isnull().sum()
            print(f"  - {col}: {missing_count}ê°œ ê²°ì¸¡ê°’ ì²˜ë¦¬")
            
            if df_processed[col].dtype in ['object', 'category']:
                # ë²”ì£¼í˜•: ìµœë¹ˆê°’ìœ¼ë¡œ ì±„ìš°ê¸°
                mode_value = df_processed[col].mode()[0] if not df_processed[col].mode().empty else 'Unknown'
                df_processed[col].fillna(mode_value, inplace=True)
                print(f"    â†’ ìµœë¹ˆê°’ '{mode_value}'ë¡œ ì±„ì›€")
            else:
                # ìˆ˜ì¹˜í˜•: ì¤‘ì•™ê°’ìœ¼ë¡œ ì±„ìš°ê¸°
                median_value = df_processed[col].median()
                df_processed[col].fillna(median_value, inplace=True)
                print(f"    â†’ ì¤‘ì•™ê°’ {median_value}ë¡œ ì±„ì›€")
        
        print(f"ê²°ì¸¡ê°’ ì²˜ë¦¬ ì™„ë£Œ: {df_processed.isnull().sum().sum()}ê°œ ë‚¨ìŒ")
        return df_processed
        
    except Exception as e:
        print(f"ê²°ì¸¡ê°’ ì „ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return df
"""
        return {
            **state,
            "nulldata_code": default_code
        }


def corr_coder_node(state: WorkflowState) -> WorkflowState:
    """
    ìƒê´€ê´€ê³„ ì „ì²˜ë¦¬ ì½”ë” ë…¸ë“œ
    
    ğŸ” INPUT STATES:
    - corr_plan: ìƒê´€ê´€ê³„ ì „ì²˜ë¦¬ ê³„íš
    - corr_eda_result: ìƒê´€ê´€ê³„ EDA ê²°ê³¼
    
    ğŸ“Š OUTPUT STATES:
    - corr_code: ìƒê´€ê´€ê³„ ì „ì²˜ë¦¬ ì½”ë“œ
    
    â¡ï¸ NEXT EDGE: executor (5ë²ˆì§¸ ìˆœì„œ)
    """
    print("ğŸ’» [CODE] ìƒê´€ê´€ê³„ ì „ì²˜ë¦¬ ì½”ë“œ ìƒì„± ì¤‘...")
    
    try:
        corr_plan = state.get("corr_plan", {})
        corr_eda = state.get("corr_eda_result", {})
        dataframe = state.get("dataframe")
        
        # ì‹¤ì œ ë°ì´í„°í”„ë ˆì„ì˜ ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ê°€ì ¸ì˜¤ê¸° (ìƒê´€ê´€ê³„ëŠ” ìˆ˜ì¹˜í˜•ì—ë§Œ ì ìš©)
        actual_numeric_columns = dataframe.select_dtypes(include=['number']).columns.tolist()
        
        kb_agent = KnowledgeBaseRAGAgent()
        kb_query = f"ìƒê´€ê´€ê³„ íŠ¹ì„±ì„ íƒ {' '.join(corr_plan.get('techniques', []))}"
        kb_result = kb_agent.search_techniques(kb_query, corr_plan.get('techniques', []))
        
        llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.1, max_tokens=1500)
        
        prompt = f"""
ë‹¹ì‹ ì€ ìƒê´€ê´€ê³„ ê¸°ë°˜ íŠ¹ì„± ì„ íƒ ì½”ë“œ ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ ê³„íšê³¼ EDA ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•œ Python ì½”ë“œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

=== ì‹¤ì œ ë°ì´í„°í”„ë ˆì„ ì •ë³´ ===
- ì „ì²´ ì»¬ëŸ¼: {list(dataframe.columns)}
- ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ (ìƒê´€ê´€ê³„ ë¶„ì„ ëŒ€ìƒ): {actual_numeric_columns}
- ë°ì´í„°í”„ë ˆì„ í¬ê¸°: {dataframe.shape}

=== ìƒê´€ê´€ê³„ ì „ì²˜ë¦¬ ê³„íš ===
ê¸°ë²•: {corr_plan.get('techniques', [])}
ê·¼ê±°: {corr_plan.get('rationale', '')}

=== EDA ê²°ê³¼ ===
ê°•í•œ ìƒê´€ê´€ê³„: {corr_eda.get('high_correlations', [])}

=== Knowledge Base ì°¸ê³  ===
{kb_result}

=== ìš”êµ¬ì‚¬í•­ ===
1. í•¨ìˆ˜ëª…: def preprocess_correlation_features(df):
2. ì…ë ¥: pandas DataFrame (ì‚¬ìš©ìê°€ ì œê³µí•œ ì‹¤ì œ ë°ì´í„°í”„ë ˆì„)
3. ì¶œë ¥: ì „ì²˜ë¦¬ëœ pandas DataFrame
4. ë°˜ë“œì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œì—¬ì•¼ í•¨
5. í•„ìš”í•œ import êµ¬ë¬¸ í¬í•¨
6. ì˜¤ë¥˜ ì²˜ë¦¬ í¬í•¨
7. ì‹¤ì œ ë°ì´í„°í”„ë ˆì„ì˜ ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ëª…ì„ ì‚¬ìš©í•˜ì„¸ìš”: {actual_numeric_columns}
8. âš ï¸ ì¤‘ìš”: ìƒˆë¡œìš´ ë°ì´í„°í”„ë ˆì„ì„ ì •ì˜í•˜ì§€ ë§ˆì„¸ìš” (df = pd.DataFrame(...) ê¸ˆì§€)
9. âš ï¸ ì¤‘ìš”: ì…ë ¥ë°›ì€ dfë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ ì „ì²˜ë¦¬í•˜ì„¸ìš”
10. âš ï¸ ì¤‘ìš”: Iris ë°ì´í„°ì˜ ì‹¤ì œ ì»¬ëŸ¼ëª… ì‚¬ìš©: {list(dataframe.columns)}

Python ì½”ë“œë§Œ ìƒì„±í•´ì£¼ì„¸ìš” (ì£¼ì„ í¬í•¨):
"""

        response = llm.invoke([HumanMessage(content=prompt)])
        generated_code = response.content
        
        if "```python" in generated_code:
            generated_code = generated_code.split("```python")[1].split("```")[0].strip()
        elif "```" in generated_code:
            generated_code = generated_code.split("```")[1].strip()
        
        print(f"âœ… [CODE] ìƒê´€ê´€ê³„ ì½”ë“œ ìƒì„± ì™„ë£Œ - {len(corr_plan.get('techniques', []))}ê°œ ê¸°ë²•")
        print("ğŸ“ [CODE] ìƒì„±ëœ ìƒê´€ê´€ê³„ ì „ì²˜ë¦¬ ì½”ë“œ:")
        print("=" * 50)
        print(generated_code)
        print("=" * 50)
        
        return {
            **state,
            "corr_code": generated_code
        }
        
    except Exception as e:
        print(f"âŒ [CODE] ìƒê´€ê´€ê³„ ì½”ë“œ ìƒì„± ì˜¤ë¥˜: {e}")
        default_code = """
import pandas as pd
import numpy as np

def preprocess_correlation_features(df):
    \"\"\"ìƒê´€ê´€ê³„ ê¸°ë°˜ íŠ¹ì„± ì„ íƒ (ê¸°ë³¸)\"\"\"
    try:
        df_processed = df.copy()
        numeric_columns = df_processed.select_dtypes(include=[np.number]).columns
        
        if len(numeric_columns) > 1:
            # ë†’ì€ ìƒê´€ê´€ê³„ íŠ¹ì„± ì œê±° (0.95 ì´ìƒ)
            corr_matrix = df_processed[numeric_columns].corr().abs()
            upper_triangle = corr_matrix.where(
                np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)
            )
            
            to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > 0.95)]
            df_processed.drop(columns=to_drop, inplace=True)
        
        return df_processed
    except Exception as e:
        print(f"ìƒê´€ê´€ê³„ ì „ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return df
"""
        return {
            **state,
            "corr_code": default_code
        } 

def code_debug_agent(state: WorkflowState) -> WorkflowState:
    """
    ì½”ë“œ ë””ë²„ê¹… ì—ì´ì „íŠ¸
    ì „ì²˜ë¦¬ ì½”ë“œ ì‹¤í–‰ ì¤‘ ë°œìƒí•œ ì˜¤ë¥˜ë¥¼ LLMì„ ì‚¬ìš©í•˜ì—¬ ìˆ˜ì •í•©ë‹ˆë‹¤.
    
    ğŸ” INPUT STATES:
    - error_message: ë°œìƒí•œ ì˜¤ë¥˜ ë©”ì‹œì§€
    - original_code: ì›ë³¸ ì „ì²˜ë¦¬ ì½”ë“œ
    - dataframe_info: ë°ì´í„°í”„ë ˆì„ ì •ë³´
    - preprocessing_plan: ì „ì²˜ë¦¬ ê³„íš
    
    ğŸ“Š OUTPUT STATES:
    - fixed_code: ìˆ˜ì •ëœ ì „ì²˜ë¦¬ ì½”ë“œ
    - debug_info: ë””ë²„ê¹… ì •ë³´
    
    â¡ï¸ NEXT EDGE: ë‹¤ì‹œ ì „ì²˜ë¦¬ ì‹¤í–‰
    """
    print("ğŸ”§ [DEBUG] ì½”ë“œ ë””ë²„ê¹… ì‹œì‘...")
    
    try:
        error_message = state.get("error_message", "")
        original_code = state.get("original_code", "")
        dataframe_info = state.get("dataframe_info", {})
        preprocessing_plan = state.get("preprocessing_plan", {})
        
        # LLMì„ ì‚¬ìš©í•˜ì—¬ ì½”ë“œ ìˆ˜ì •
        llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.1, max_tokens=2000)
        
        prompt = f"""
ë‹¹ì‹ ì€ Python ì½”ë“œ ë””ë²„ê¹… ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì „ì²˜ë¦¬ ì½”ë“œ ì‹¤í–‰ ì¤‘ ë°œìƒí•œ ì˜¤ë¥˜ë¥¼ ë¶„ì„í•˜ê³  ìˆ˜ì •í•´ì£¼ì„¸ìš”.

=== ì˜¤ë¥˜ ë©”ì‹œì§€ ===
{error_message}

=== ì›ë³¸ ì „ì²˜ë¦¬ ì½”ë“œ ===
{original_code}

=== ë°ì´í„°í”„ë ˆì„ ì •ë³´ ===
{json.dumps(dataframe_info, indent=2, ensure_ascii=False)}

=== ì „ì²˜ë¦¬ ê³„íš ===
{json.dumps(preprocessing_plan, indent=2, ensure_ascii=False)}

=== ë””ë²„ê¹… ì§€ì¹¨ ===
1. **ì˜¤ë¥˜ ë¶„ì„**: ì˜¤ë¥˜ì˜ ì›ì¸ì„ ì •í™•íˆ íŒŒì•…í•˜ì„¸ìš”
2. **ì½”ë“œ ê²€í† **: ì›ë³¸ ì½”ë“œì˜ ë¬¸ì œì ì„ ì°¾ìœ¼ì„¸ìš”
3. **ìˆ˜ì • ë°©ì•ˆ**: êµ¬ì²´ì ì¸ ìˆ˜ì • ë°©ë²•ì„ ì œì‹œí•˜ì„¸ìš”
4. **ì½”ë“œ ìˆ˜ì •**: ìˆ˜ì •ëœ ì™„ì „í•œ ì½”ë“œë¥¼ ì œê³µí•˜ì„¸ìš”

=== ìˆ˜ì • ì‹œ ê³ ë ¤ì‚¬í•­ ===
- ì»¬ëŸ¼ëª…ì´ ì‹¤ì œ ë°ì´í„°í”„ë ˆì„ì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
- ë°ì´í„° íƒ€ì…ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸
- í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ importë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
- ë³€ìˆ˜ëª…ê³¼ í•¨ìˆ˜ëª…ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸
- ì˜ˆì™¸ ì²˜ë¦¬ê°€ ì ì ˆí•œì§€ í™•ì¸

=== ì‘ë‹µ í˜•ì‹ ===
{{
    "error_analysis": "ì˜¤ë¥˜ ì›ì¸ ë¶„ì„",
    "fix_strategy": "ìˆ˜ì • ì „ëµ",
    "fixed_code": "ìˆ˜ì •ëœ ì™„ì „í•œ ì½”ë“œ",
    "debug_info": {{
        "original_error": "ì›ë³¸ ì˜¤ë¥˜",
        "fix_description": "ìˆ˜ì • ë‚´ìš© ì„¤ëª…",
        "prevention_tips": "í–¥í›„ ì˜ˆë°© ë°©ë²•"
    }}
}}

JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
"""

        response = llm.invoke([HumanMessage(content=prompt)])
        
        # JSON íŒŒì‹±
        try:
            content = response.content.strip()
            if content.startswith('```json'):
                content = content.split('```json')[1].split('```')[0].strip()
            elif content.startswith('```'):
                content = content.split('```')[1].split('```')[0].strip()
            
            result = json.loads(content)
        except (json.JSONDecodeError, IndexError) as e:
            print(f"âš ï¸ [DEBUG] JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            result = {
                "error_analysis": "JSON íŒŒì‹± ì‹¤íŒ¨",
                "fix_strategy": "ê¸°ë³¸ ìˆ˜ì • ì „ëµ",
                "fixed_code": original_code,
                "debug_info": {
                    "original_error": error_message,
                    "fix_description": "íŒŒì‹± ì˜¤ë¥˜ë¡œ ì¸í•œ ê¸°ë³¸ ìˆ˜ì •",
                    "prevention_tips": "JSON ì‘ë‹µ í˜•ì‹ í™•ì¸ í•„ìš”"
                }
            }
        
        debug_info = {
            "error_analysis": result.get("error_analysis", ""),
            "fix_strategy": result.get("fix_strategy", ""),
            "debug_info": result.get("debug_info", {}),
            "original_error": error_message,
            "original_code": original_code
        }
        
        print(f"âœ… [DEBUG] ì½”ë“œ ë””ë²„ê¹… ì™„ë£Œ")
        
        # ë””ë²„ê¹… ê²°ê³¼ ë¡œê¹…
        print("\n" + "="*50)
        print("ğŸ”§ [DEBUG] ì½”ë“œ ë””ë²„ê¹… ê²°ê³¼")
        print("="*50)
        print(f"ğŸ“Š ì˜¤ë¥˜ ë¶„ì„: {debug_info['error_analysis']}")
        print(f"ğŸ”§ ìˆ˜ì • ì „ëµ: {debug_info['fix_strategy']}")
        print(f"ğŸ’¡ ì˜ˆë°© ë°©ë²•: {debug_info['debug_info'].get('prevention_tips', 'N/A')}")
        
        return {
            **state,
            "fixed_code": result.get("fixed_code", original_code),
            "debug_info": debug_info,
            "debug_status": "success"
        }
        
    except Exception as e:
        print(f"âŒ [DEBUG] ì½”ë“œ ë””ë²„ê¹… ì˜¤ë¥˜: {e}")
        return {
            **state,
            "fixed_code": original_code,
            "debug_info": {
                "error_analysis": f"ë””ë²„ê¹… ìì²´ ì˜¤ë¥˜: {str(e)}",
                "fix_strategy": "ê¸°ë³¸ ì½”ë“œ ìœ ì§€",
                "debug_info": {
                    "original_error": error_message,
                    "fix_description": "ë””ë²„ê¹… ì‹¤íŒ¨ë¡œ ì›ë³¸ ì½”ë“œ ìœ ì§€",
                    "prevention_tips": "ë””ë²„ê¹… ì‹œìŠ¤í…œ ì ê²€ í•„ìš”"
                }
            },
            "debug_status": "error"
        } 