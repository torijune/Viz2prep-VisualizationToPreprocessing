"""
ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ìŠ¤ì¼€ì¼ë§ ì „ì²˜ë¦¬ ì—ì´ì „íŠ¸
ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë¥¼ ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ ìŠ¤ì¼€ì¼ë§í•©ë‹ˆë‹¤.
"""

import pandas as pd
import numpy as np
from typing import Dict, Any, List, Optional
from langchain_core.runnables import RunnableLambda
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage


def handle_scaling(inputs: Dict[str, Any]) -> Dict[str, Any]:
    """
    ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë¥¼ ìŠ¤ì¼€ì¼ë§í•˜ëŠ” ì „ì²˜ë¦¬ ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.
    
    Args:
        inputs: X, Y DataFrameê³¼ EDA ê²°ê³¼ê°€ í¬í•¨ëœ ì…ë ¥ ë”•ì…”ë„ˆë¦¬
        
    Returns:
        ì „ì²˜ë¦¬ëœ X, Y DataFrameê³¼ ì½”ë“œê°€ í¬í•¨ëœ ë”•ì…”ë„ˆë¦¬
    """
    print("ğŸ”§ [PREPROCESSING] ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ìŠ¤ì¼€ì¼ë§ ì‹œì‘...")
    
    X = inputs["X"]
    Y = inputs["Y"]
    eda_results = inputs.get("eda_results", {})
    
    # Xì™€ Yì˜ ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ì°¾ê¸°
    X_numeric_columns = X.select_dtypes(include=[np.number]).columns.tolist()
    Y_numeric_columns = Y.select_dtypes(include=[np.number]).columns.tolist()
    
    if not X_numeric_columns and not Y_numeric_columns:
        print("âœ… [PREPROCESSING] ìˆ˜ì¹˜í˜• ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return {
            **inputs,
            "preprocessing_code": "# ìˆ˜ì¹˜í˜• ë³€ìˆ˜ê°€ ì—†ìœ¼ë¯€ë¡œ ìŠ¤ì¼€ì¼ë§ ë¶ˆí•„ìš”",
            "preprocessing_summary": "ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ì—†ìŒ"
        }
    
    print(f"ğŸ“Š [PREPROCESSING] X ìˆ˜ì¹˜í˜• ë³€ìˆ˜: {X_numeric_columns}")
    print(f"ğŸ“Š [PREPROCESSING] Y ìˆ˜ì¹˜í˜• ë³€ìˆ˜: {Y_numeric_columns}")
    
    # ìŠ¤ì¼€ì¼ë§ ì „ëµ ê²°ì •
    X_scaling_steps = []
    Y_scaling_steps = []
    
    # X ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ì²˜ë¦¬ (íŠ¹ì„± ë³€ìˆ˜ëŠ” ìŠ¤ì¼€ì¼ë§ í•„ìš”)
    for col in X_numeric_columns:
        # ë¶„ì‚°ê³¼ ë²”ìœ„ë¥¼ í™•ì¸í•˜ì—¬ ìŠ¤ì¼€ì¼ë§ ë°©ë²• ê²°ì •
        std_dev = X[col].std()
        value_range = X[col].max() - X[col].min()
        
        if std_dev > 1 or value_range > 10:
            # í‘œì¤€í¸ì°¨ê°€ í¬ê±°ë‚˜ ë²”ìœ„ê°€ ë„“ìœ¼ë©´ StandardScaler
            X_scaling_steps.append({
                'column': col,
                'method': 'standard',
                'reason': f'í‘œì¤€í¸ì°¨ {std_dev:.2f}, ë²”ìœ„ {value_range:.2f}'
            })
            print(f"   ğŸ“Š [PREPROCESSING] X {col}: StandardScaler")
        else:
            # ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ MinMaxScaler
            X_scaling_steps.append({
                'column': col,
                'method': 'minmax',
                'reason': f'í‘œì¤€í¸ì°¨ {std_dev:.2f}, ë²”ìœ„ {value_range:.2f}'
            })
            print(f"   ğŸ“Š [PREPROCESSING] X {col}: MinMaxScaler")
    
    # Y ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ì²˜ë¦¬ (íƒ€ê²Ÿ ë³€ìˆ˜ëŠ” ë³´í†µ ìŠ¤ì¼€ì¼ë§í•˜ì§€ ì•ŠìŒ, í•˜ì§€ë§Œ í•„ìš”ì‹œ ì²˜ë¦¬)
    for col in Y_numeric_columns:
        # íƒ€ê²Ÿ ë³€ìˆ˜ëŠ” íšŒê·€ ë¬¸ì œì—ì„œë§Œ ìŠ¤ì¼€ì¼ë§ ê³ ë ¤
        Y_scaling_steps.append({
            'column': col,
            'method': 'none',
            'reason': 'íƒ€ê²Ÿ ë³€ìˆ˜ëŠ” ìŠ¤ì¼€ì¼ë§í•˜ì§€ ì•ŠìŒ'
        })
        print(f"   ğŸ“Š [PREPROCESSING] Y {col}: ìŠ¤ì¼€ì¼ë§í•˜ì§€ ì•ŠìŒ (íƒ€ê²Ÿ ë³€ìˆ˜)")
    
    # ì „ì²˜ë¦¬ ì½”ë“œ ìƒì„±
    print("ğŸ’» [PREPROCESSING] ìŠ¤ì¼€ì¼ë§ ì½”ë“œ ìƒì„± ì¤‘...")
    
    code_lines = [
        "# ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ìŠ¤ì¼€ì¼ë§ (X/Y ë¶„ë¦¬)",
        "import pandas as pd",
        "import numpy as np",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler",
        "",
        "def scale_numeric_variables(X, Y):",
        "    \"\"\"Xì™€ Yì˜ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë¥¼ ìŠ¤ì¼€ì¼ë§í•˜ëŠ” í•¨ìˆ˜\"\"\"",
        "    X_processed = X.copy()",
        "    Y_processed = Y.copy()",
        ""
    ]
    
    # X ìŠ¤ì¼€ì¼ë§ ì½”ë“œ ì¶”ê°€
    if X_scaling_steps:
        code_lines.append("    # X ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ìŠ¤ì¼€ì¼ë§")
        
        # StandardScalerê°€ í•„ìš”í•œ ì»¬ëŸ¼ë“¤
        X_standard_cols = [step['column'] for step in X_scaling_steps if step['method'] == 'standard']
        if X_standard_cols:
            code_lines.extend([
                "    # StandardScaler ì ìš©",
                "    standard_scaler = StandardScaler()",
                f"    X_processed[{X_standard_cols}] = standard_scaler.fit_transform(X_processed[{X_standard_cols}])",
                f"    print(f'X ì»¬ëŸ¼ {X_standard_cols} StandardScaler ì ìš© ì™„ë£Œ')",
                ""
            ])
        
        # MinMaxScalerê°€ í•„ìš”í•œ ì»¬ëŸ¼ë“¤
        X_minmax_cols = [step['column'] for step in X_scaling_steps if step['method'] == 'minmax']
        if X_minmax_cols:
            code_lines.extend([
                "    # MinMaxScaler ì ìš©",
                "    minmax_scaler = MinMaxScaler()",
                f"    X_processed[{X_minmax_cols}] = minmax_scaler.fit_transform(X_processed[{X_minmax_cols}])",
                f"    print(f'X ì»¬ëŸ¼ {X_minmax_cols} MinMaxScaler ì ìš© ì™„ë£Œ')",
                ""
            ])
    
    # Y ìŠ¤ì¼€ì¼ë§ ì½”ë“œ ì¶”ê°€ (ë³´í†µ ìŠ¤ì¼€ì¼ë§í•˜ì§€ ì•ŠìŒ)
    if Y_scaling_steps:
        code_lines.append("    # Y ìˆ˜ì¹˜í˜• ë³€ìˆ˜ (íƒ€ê²Ÿ ë³€ìˆ˜ëŠ” ë³´í†µ ìŠ¤ì¼€ì¼ë§í•˜ì§€ ì•ŠìŒ)")
        code_lines.append("    # í•„ìš”ì‹œ ì•„ë˜ ì£¼ì„ì„ í•´ì œí•˜ì—¬ ìŠ¤ì¼€ì¼ë§ ì ìš©")
        code_lines.append("    # Y_numeric_cols = Y_processed.select_dtypes(include=[np.number]).columns")
        code_lines.append("    # if len(Y_numeric_cols) > 0:")
        code_lines.append("    #     Y_scaler = StandardScaler()")
        code_lines.append("    #     Y_processed[Y_numeric_cols] = Y_scaler.fit_transform(Y_processed[Y_numeric_cols])")
        code_lines.append("")
    
    code_lines.extend([
        "    return X_processed, Y_processed",
        "",
        "# ì „ì²˜ë¦¬ ì‹¤í–‰",
        "X_processed, Y_processed = scale_numeric_variables(X, Y)"
    ])
    
    preprocessing_code = "\n".join(code_lines)
    
    # ì „ì²˜ë¦¬ ì‹¤í–‰
    print("ğŸ”„ [PREPROCESSING] ìŠ¤ì¼€ì¼ë§ ì‹¤í–‰ ì¤‘...")
    try:
        X_processed, Y_processed = apply_basic_scaling(X, Y, X_scaling_steps, Y_scaling_steps)
        
        print(f"âœ… [PREPROCESSING] ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ")
        print(f"   ğŸ“Š [PREPROCESSING] X: {X.shape} â†’ {X_processed.shape}")
        print(f"   ğŸ“Š [PREPROCESSING] Y: {Y.shape} â†’ {Y_processed.shape}")
        
        return {
            **inputs,
            "X_processed": X_processed,
            "Y_processed": Y_processed,
            "preprocessing_code": preprocessing_code,
            "preprocessing_summary": {
                "X_numeric_scaled": len(X_scaling_steps),
                "Y_numeric_scaled": len([s for s in Y_scaling_steps if s['method'] != 'none']),
                "X_standard_scaled": len([s for s in X_scaling_steps if s['method'] == 'standard']),
                "X_minmax_scaled": len([s for s in X_scaling_steps if s['method'] == 'minmax'])
            }
        }
        
    except Exception as e:
        print(f"âŒ [PREPROCESSING] ìŠ¤ì¼€ì¼ë§ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        return {
            **inputs,
            "preprocessing_code": preprocessing_code,
            "preprocessing_summary": f"ìŠ¤ì¼€ì¼ë§ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}"
        }


def apply_basic_scaling(X: pd.DataFrame, Y: pd.DataFrame,
                       X_steps: List[Dict], Y_steps: List[Dict]) -> tuple:
    """
    ê¸°ë³¸ì ì¸ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ìŠ¤ì¼€ì¼ë§ì„ ì ìš©í•©ë‹ˆë‹¤.
    
    Args:
        X: íŠ¹ì„± ë³€ìˆ˜ ë°ì´í„°í”„ë ˆì„
        Y: íƒ€ê²Ÿ ë³€ìˆ˜ ë°ì´í„°í”„ë ˆì„
        X_steps: X ìŠ¤ì¼€ì¼ë§ ë‹¨ê³„ë“¤
        Y_steps: Y ìŠ¤ì¼€ì¼ë§ ë‹¨ê³„ë“¤
        
    Returns:
        tuple: (X_processed, Y_processed) ì²˜ë¦¬ëœ ë°ì´í„°í”„ë ˆì„ë“¤
    """
    X_processed = X.copy()
    Y_processed = Y.copy()
    
    # X ì²˜ë¦¬
    for step in X_steps:
        col = step['column']
        method = step['method']
        
        if method == 'standard':
            from sklearn.preprocessing import StandardScaler
            scaler = StandardScaler()
            X_processed[col] = scaler.fit_transform(X_processed[[col]])
            
        elif method == 'minmax':
            from sklearn.preprocessing import MinMaxScaler
            scaler = MinMaxScaler()
            X_processed[col] = scaler.fit_transform(X_processed[[col]])
            
        elif method == 'robust':
            from sklearn.preprocessing import RobustScaler
            scaler = RobustScaler()
            X_processed[col] = scaler.fit_transform(X_processed[[col]])
    
    # Y ì²˜ë¦¬ (ë³´í†µ ìŠ¤ì¼€ì¼ë§í•˜ì§€ ì•ŠìŒ)
    for step in Y_steps:
        col = step['column']
        method = step['method']
        
        if method != 'none':
            # í•„ìš”ì‹œ Yë„ ìŠ¤ì¼€ì¼ë§
            from sklearn.preprocessing import StandardScaler
            scaler = StandardScaler()
            Y_processed[col] = scaler.fit_transform(Y_processed[[col]])
    
    return X_processed, Y_processed


def apply_manual_scaling(X: pd.DataFrame, Y: pd.DataFrame,
                        method: str, inputs: Dict) -> tuple:
    """
    ì‚¬ìš©ìê°€ ì§€ì •í•œ ë°©ë²•ìœ¼ë¡œ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë¥¼ ìŠ¤ì¼€ì¼ë§í•©ë‹ˆë‹¤.
    
    Args:
        X: íŠ¹ì„± ë³€ìˆ˜ ë°ì´í„°í”„ë ˆì„
        Y: íƒ€ê²Ÿ ë³€ìˆ˜ ë°ì´í„°í”„ë ˆì„
        method: ìŠ¤ì¼€ì¼ë§ ë°©ë²•
        inputs: ì¶”ê°€ ì…ë ¥ ì •ë³´
        
    Returns:
        tuple: (X_processed, Y_processed) ì²˜ë¦¬ëœ ë°ì´í„°í”„ë ˆì„ë“¤
    """
    X_processed = X.copy()
    Y_processed = Y.copy()
    
    if method == "all_standard":
        # ëª¨ë“  ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë¥¼ StandardScalerë¡œ ìŠ¤ì¼€ì¼ë§
        from sklearn.preprocessing import StandardScaler
        
        X_numeric = X_processed.select_dtypes(include=[np.number])
        Y_numeric = Y_processed.select_dtypes(include=[np.number])
        
        if len(X_numeric.columns) > 0:
            X_scaler = StandardScaler()
            X_processed[X_numeric.columns] = X_scaler.fit_transform(X_numeric)
            
        if len(Y_numeric.columns) > 0:
            Y_scaler = StandardScaler()
            Y_processed[Y_numeric.columns] = Y_scaler.fit_transform(Y_numeric)
            
    elif method == "all_minmax":
        # ëª¨ë“  ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë¥¼ MinMaxScalerë¡œ ìŠ¤ì¼€ì¼ë§
        from sklearn.preprocessing import MinMaxScaler
        
        X_numeric = X_processed.select_dtypes(include=[np.number])
        Y_numeric = Y_processed.select_dtypes(include=[np.number])
        
        if len(X_numeric.columns) > 0:
            X_scaler = MinMaxScaler()
            X_processed[X_numeric.columns] = X_scaler.fit_transform(X_numeric)
            
        if len(Y_numeric.columns) > 0:
            Y_scaler = MinMaxScaler()
            Y_processed[Y_numeric.columns] = Y_scaler.fit_transform(Y_numeric)
            
    elif method == "robust":
        # RobustScaler ì‚¬ìš© (ì´ìƒì¹˜ì— ê°•í•¨)
        from sklearn.preprocessing import RobustScaler
        
        X_numeric = X_processed.select_dtypes(include=[np.number])
        Y_numeric = Y_processed.select_dtypes(include=[np.number])
        
        if len(X_numeric.columns) > 0:
            X_scaler = RobustScaler()
            X_processed[X_numeric.columns] = X_scaler.fit_transform(X_numeric)
            
        if len(Y_numeric.columns) > 0:
            Y_scaler = RobustScaler()
            Y_processed[Y_numeric.columns] = Y_scaler.fit_transform(Y_numeric)
    
    return X_processed, Y_processed


# LangChain Runnableìœ¼ë¡œ ë“±ë¡
scaling_agent = RunnableLambda(handle_scaling)